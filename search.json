[
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Topic\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nLecture\n\n\nDate\n\n\nTopic\n\n\n\n\n\n\nLecture 0\n\n\n2025-03-24\n\n\nCourse introduction\n\n\n\n\nLecture 1\n\n\n2025-03-24\n\n\nPopulations, samples, variable types and descriptive statistics\n\n\n\n\nLecture 2\n\n\n2025-03-27\n\n\nThe scientific method\n\n\n\n\nLecture 3\n\n\n2025-03-31\n\n\nUncertainty, sampling error and confidence intervals\n\n\n\n\nLecture 4\n\n\n2025-04-01\n\n\nComparing means of multiple groups\n\n\n\n\nLecture 5\n\n\n2025-04-01\n\n\nTheory based statistics (when sample sizes are small)\n\n\n\n\nLecture 6\n\n\n2025-04-02\n\n\nTest of and associations between categorical variables\n\n\n\n\nLecture 7\n\n\n2025-04-02\n\n\nExperimental design discussion slides\n\n\n\n\nLecture 8\n\n\n2025-04-04\n\n\nCorrelation, Causation, and Linear Regression\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "exercises/11_article_exercise.html",
    "href": "exercises/11_article_exercise.html",
    "title": "Article exercise",
    "section": "",
    "text": "In this assignment you will read the introduction and methods sections of a published research paper. However, the results and discussion sections have been removed, as have most references to statistical methods used. For this exercise to be useful, please do not look-up the original paper. This is not a test, it is a learning exercise.\nThe redacted version of the paper can be downloaded here.\nThe dataset the researchers collected can be downloaded here.\nYour task is to:\n\nIdentify the research questions and hypotheses of the study.\nDesign a set of statistical methods to test those hypotheses, given the data the authors collected, and write the missing Statistical analysis section of the methods section.\nCarry out those statistical tests, and produce tables and figures that could make up the missing Results section of the paper.\n\n\n\nRead through the paper, and highlight any sentence that could form a testable hypothesis. For example on page 3:\n\n“we expected that males perceiving high-density environments would have larger testes and accessory glands (that produce seminal fluid) due to increased sperm competition.”\n\nThis is a clear statement of a hypothesis about how perceived population density could have a directional effect on testes and accessory gland size.\nIdentify at least one hypothesis from the paper in each of the following topics:\n\nMetabolic rate\nReproductive investment\nAggressive behaviours\nSong characteristics\n\nIf while reading you develop your own own hypotheses, you can also add them.\n\n\n\nBefore moving any further, now would be a good time to see what data you have to work with. I suggest you setup RStudio and a RMarkdown file if you haven’t already. Use the guides below to help.\n\n\n\n\n\n\nHow to setup RStudio\n\n\n\n\n\n\nMake a new folder in your course folder for the exercise (e.g. biob11/writing_assignment)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\n\n\n\n\n\n\n\n\n\nHelpful functions\n\n\n\n\n\n\nlibrary(package-name) to load a package.\nread_csv(\"filename_of_file.csv\") to load a csv file (requires tidyverse).\nfilter() to subset the data based on specific conditions (requires tidyverse).\ngroup_by() to group the data by one or more variables (requires tidyverse).\nsummarise() to calculate summary statistics (e.g., mean, median, sum) for each group (requires tidyverse).\n\n\n\n\nThe dataset (download link at the top of the page) contains 29 variables. You are not requried to use them all. A basic definition is given for each variable below, but consulting the original paper is required to fully understand what each means, and to decide how to use it properly in a statistical test. The dataset also contains many NA values, as not all crickets were used for all experiments. Be mindful of this when working with it.\n\n\n\n\n\n\nVariable definitions\n\n\n\n\n\n\n\n\ncricket_id: identifier of the cricket\njuvenile_environment: either high_density or low_density\n\n\n\n\n\nresp_mass_g: mass in grams of the cricket prior to the respiration measurements\nresp_age_days: age of the cricket in days prior to the respiration measurements\nresp_volume_co2: rate of \\(\\text{CO}_2\\) production (μL/min)\nresp_volume_o2: rate of \\(\\text{O}_2\\) consumption (μL/min)\n\n\n\n\n\ndis_mass_g: mass in grams of the cricket prior to the disection\ndis_age_days: age of the cricket in days prior to disection\ndis_accessory_g: mass in grams of the accessory glands\ndis_testes_g: mass in grams of the testes\n\n\n\n\n\nsong_mass_g: mass in grams of the cricket prior to the song measurements\nsong_age_days: age of the cricket in days prior to song measurements\nsong_chirp_rate: probably chirps per second\nsong_chirp_duration: length of chirps (seconds)\nsong_pulses_per_chirp: average number of pulses per chirp\nsong_pulse_duration: average length of pulse duration\nsong_dominant_frequency: song dominant frequency (kHz)\n\n\n\n\n\nagg_mass_g: mass in grams of the cricket prior to the aggresion trials\nagg_age_days: age of the cricket in days prior to the aggression trials\nagg_trial_id: identifier of the trial (shared between two crickets)\nagg_winner: was the cricket deemed to have won the aggression trial?\nagg_dot_colour: the colour dot that was used to identify the cricket in the trial\nagg_female_present: did the trial have a female present in the center of the arena?\nagg_num_wins: the number of battles the cricket won\nagg_num_battles: the total number of battles in the trial\nagg_first_behaviour: was the cricket the first in the trial to show an aggressive behaviour?\nagg_first_song: was the cricket the first in the trial to sing aggressively?\nagg_first_song_length: length of the first aggressive song the cricket sang.\nagg_first_winner: was the cricket the winner of the first aggressive encounter?\n\n\n\n\n\nOnce you have the dataset loaded, and have a general idea of the data available to you, move to the next section.\n\n\n\nTake each of your identified hypotheses and complete the following steps:\n\nDecide which variables you can use to test it. What are your response and explanatory variables?\nDecide on a test statistic (mean, variance, standard deviation, difference in means, \\(F\\), \\(\\chi^2\\), correlation, etc) that would be best to address the hypothesis.\nTurn the hypothesis into a clear null and alternative hypothesis. Make sure to indicate the direction (lesser, greater, two-sided) if appropriate.\nWrite a short paragraph that could be used in the statistical analysis section in the paper.\n\n\n\n\n\n\n\nGuide on how to write about a statistical analysis\n\n\n\n\n\nFor each statistical approach, include the following in your text:\n\nObjective: Describe the rationale for the analysis and how it relates to the study objective.\nVariables: Define the experimental unit and the response and explanatory variables clearly.\nStatistical method: Describe the statistical method (e.g., ANOVA, difference in means, linear regression). How was the null distribution generated? What (if any) \\(\\alpha\\) value will you use (e.g., \\(\\alpha\\) = 0.05?). How will you calculate the p-value?\nImplementation: Describe the function (e.g., calculate() from the infer package), package (e.g. infer), and software (e.g., R version 4.4.1) used and include any appropriate citations.\n\n\n\n\n\n\n\n\n\n\nHow to cite R correctly\n\n\n\n\n\nTo generate a citation for R itself, you can run:\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo get the name of the version of R you are running:\n\nR.version.string\n\n[1] \"R version 4.4.1 (2024-06-14)\"\n\n\nTo get the citation for any package you are using:\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\n\ncitation(\"infer\")\n\nTo cite package 'infer' in publications use:\n\n  Couch et al., (2021). infer: An R package for tidyverse-friendly\n  statistical inference. Journal of Open Source Software, 6(65), 3661,\n  https://doi.org/10.21105/joss.03661\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {{infer}: An {R} package for tidyverse-friendly statistical inference},\n    author = {Simon P. Couch and Andrew P. Bray and Chester Ismay and Evgeni Chasnovski and Benjamin S. Baumer and Mine Çetinkaya-Rundel},\n    journal = {Journal of Open Source Software},\n    year = {2021},\n    volume = {6},\n    number = {65},\n    pages = {3661},\n    doi = {10.21105/joss.03661},\n  }\n\n\n\n\n\n\n\n\nUse summarize() and ggplot() to create a set of tables/figures that illustrate each hypothesis. You should create at least 4 tables/figures (one for each topic). You will refer to these tables/figures in your results section. Ensure that any plot clearly shows the variables in questions and that the axis are clearly labelled.\nAnytime you report a value in a table, try and also provide 95% confidence intervals (if approportiate).\n\n\n\n\n\n\nggplot2 quick guide\n\n\n\n\n\n\n1my_data |&gt;\n2  ggplot(mapping = aes(x = _____, y = _____, colour = _____, fill = _____)) +\n3  geom_____() +\n4  labs(x = _____, y = _____, title = _____) +\n5  theme______()\n\n\n1\n\nYour dataset.\n\n2\n\nIdentify which variables should be mapped to which features of the plot.\n\n3\n\nIdentify what geometries you will use. More than one is allowed!\n\n4\n\nGive your plot clear axis labels.\n\n5\n\nChange the theme if you wish.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown tables quick guide\n\n\n\n\n\nIf you would like your tables to format nicely when you “knit” your RMarkdown file, you can pipe them into the knitr function called kable(). You need to either load the knitr package first, or you can simply write knitr::kable(). This syntax allows R to access a single function within a package, without loading the whole package.\nWhen the document is knitted, they will look nice:\n\niris |&gt; \n  group_by(Species) |&gt;\n  summarise(\n    n = n(),\n    mean_sepal_length = mean(Sepal.Length),\n    mean_petal_length = mean(Petal.Length)\n    ) |&gt;\n  knitr::kable()\n\n\n\n\nSpecies\nn\nmean_sepal_length\nmean_petal_length\n\n\n\n\nsetosa\n50\n5.006\n1.462\n\n\nversicolor\n50\n5.936\n4.260\n\n\nvirginica\n50\n6.588\n5.552\n\n\n\n\n\n\n\n\n\n\n\nUse what you have learned during the course so far to conduct the analysis you have described. Make use of the infer package. Use examples from previous exercises, or from the infer set of examples. Record the outcome of each test in the RMarkdown document.\n\n\n\nA results section is where you report your findings to all the hypotheses laid out in the introduction and methods. You have already described your statistical analysis in the methods section, so there is no need to go into great detail here. Importantly, in a paper with separate results and discussion sections, you should not discuss your findings in the results section, only report them. Any time you report a result, you should back it up with a statistic, and a relevant figure. A helpful two part structure you can follow for each result is the following:\n\nReport the overall result in plain language. If the reader reads only this sentence, they should get the whole picture in broad terms.\n\n\nPerceived population density during development had X effect on reproductive investment.\n\n\nReport the result in more specific terms. Make reference to the source of your results, such as statistical tests, tables and figures. You may have several sentences like this for each overall result.\n\n\nAccessory gland mass [did/did not] differ significantly between males reared in high or low densities (difference in means test, diff = X, $p = Y, figure Z).\n\n\n\n\nOften the title of a paper will summarise the results in a single line. Can you think of a good title that summarises what you found?\n\n\n\nOnce you are finished with the exercise (or at the end of the exercise session if you have not finished), submit your work to the Canvas assignment. You will not be graded, and instead I will provide broad feedback to the class."
  },
  {
    "objectID": "exercises/11_article_exercise.html#identify-the-hypotheses",
    "href": "exercises/11_article_exercise.html#identify-the-hypotheses",
    "title": "Article exercise",
    "section": "",
    "text": "Read through the paper, and highlight any sentence that could form a testable hypothesis. For example on page 3:\n\n“we expected that males perceiving high-density environments would have larger testes and accessory glands (that produce seminal fluid) due to increased sperm competition.”\n\nThis is a clear statement of a hypothesis about how perceived population density could have a directional effect on testes and accessory gland size.\nIdentify at least one hypothesis from the paper in each of the following topics:\n\nMetabolic rate\nReproductive investment\nAggressive behaviours\nSong characteristics\n\nIf while reading you develop your own own hypotheses, you can also add them."
  },
  {
    "objectID": "exercises/11_article_exercise.html#understand-the-data",
    "href": "exercises/11_article_exercise.html#understand-the-data",
    "title": "Article exercise",
    "section": "",
    "text": "Before moving any further, now would be a good time to see what data you have to work with. I suggest you setup RStudio and a RMarkdown file if you haven’t already. Use the guides below to help.\n\n\n\n\n\n\nHow to setup RStudio\n\n\n\n\n\n\nMake a new folder in your course folder for the exercise (e.g. biob11/writing_assignment)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\n\n\n\n\n\n\n\n\n\nHelpful functions\n\n\n\n\n\n\nlibrary(package-name) to load a package.\nread_csv(\"filename_of_file.csv\") to load a csv file (requires tidyverse).\nfilter() to subset the data based on specific conditions (requires tidyverse).\ngroup_by() to group the data by one or more variables (requires tidyverse).\nsummarise() to calculate summary statistics (e.g., mean, median, sum) for each group (requires tidyverse).\n\n\n\n\nThe dataset (download link at the top of the page) contains 29 variables. You are not requried to use them all. A basic definition is given for each variable below, but consulting the original paper is required to fully understand what each means, and to decide how to use it properly in a statistical test. The dataset also contains many NA values, as not all crickets were used for all experiments. Be mindful of this when working with it.\n\n\n\n\n\n\nVariable definitions\n\n\n\n\n\n\n\n\ncricket_id: identifier of the cricket\njuvenile_environment: either high_density or low_density\n\n\n\n\n\nresp_mass_g: mass in grams of the cricket prior to the respiration measurements\nresp_age_days: age of the cricket in days prior to the respiration measurements\nresp_volume_co2: rate of \\(\\text{CO}_2\\) production (μL/min)\nresp_volume_o2: rate of \\(\\text{O}_2\\) consumption (μL/min)\n\n\n\n\n\ndis_mass_g: mass in grams of the cricket prior to the disection\ndis_age_days: age of the cricket in days prior to disection\ndis_accessory_g: mass in grams of the accessory glands\ndis_testes_g: mass in grams of the testes\n\n\n\n\n\nsong_mass_g: mass in grams of the cricket prior to the song measurements\nsong_age_days: age of the cricket in days prior to song measurements\nsong_chirp_rate: probably chirps per second\nsong_chirp_duration: length of chirps (seconds)\nsong_pulses_per_chirp: average number of pulses per chirp\nsong_pulse_duration: average length of pulse duration\nsong_dominant_frequency: song dominant frequency (kHz)\n\n\n\n\n\nagg_mass_g: mass in grams of the cricket prior to the aggresion trials\nagg_age_days: age of the cricket in days prior to the aggression trials\nagg_trial_id: identifier of the trial (shared between two crickets)\nagg_winner: was the cricket deemed to have won the aggression trial?\nagg_dot_colour: the colour dot that was used to identify the cricket in the trial\nagg_female_present: did the trial have a female present in the center of the arena?\nagg_num_wins: the number of battles the cricket won\nagg_num_battles: the total number of battles in the trial\nagg_first_behaviour: was the cricket the first in the trial to show an aggressive behaviour?\nagg_first_song: was the cricket the first in the trial to sing aggressively?\nagg_first_song_length: length of the first aggressive song the cricket sang.\nagg_first_winner: was the cricket the winner of the first aggressive encounter?\n\n\n\n\n\nOnce you have the dataset loaded, and have a general idea of the data available to you, move to the next section."
  },
  {
    "objectID": "exercises/11_article_exercise.html#design-the-statistical-analysis",
    "href": "exercises/11_article_exercise.html#design-the-statistical-analysis",
    "title": "Article exercise",
    "section": "",
    "text": "Take each of your identified hypotheses and complete the following steps:\n\nDecide which variables you can use to test it. What are your response and explanatory variables?\nDecide on a test statistic (mean, variance, standard deviation, difference in means, \\(F\\), \\(\\chi^2\\), correlation, etc) that would be best to address the hypothesis.\nTurn the hypothesis into a clear null and alternative hypothesis. Make sure to indicate the direction (lesser, greater, two-sided) if appropriate.\nWrite a short paragraph that could be used in the statistical analysis section in the paper.\n\n\n\n\n\n\n\nGuide on how to write about a statistical analysis\n\n\n\n\n\nFor each statistical approach, include the following in your text:\n\nObjective: Describe the rationale for the analysis and how it relates to the study objective.\nVariables: Define the experimental unit and the response and explanatory variables clearly.\nStatistical method: Describe the statistical method (e.g., ANOVA, difference in means, linear regression). How was the null distribution generated? What (if any) \\(\\alpha\\) value will you use (e.g., \\(\\alpha\\) = 0.05?). How will you calculate the p-value?\nImplementation: Describe the function (e.g., calculate() from the infer package), package (e.g. infer), and software (e.g., R version 4.4.1) used and include any appropriate citations.\n\n\n\n\n\n\n\n\n\n\nHow to cite R correctly\n\n\n\n\n\nTo generate a citation for R itself, you can run:\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo get the name of the version of R you are running:\n\nR.version.string\n\n[1] \"R version 4.4.1 (2024-06-14)\"\n\n\nTo get the citation for any package you are using:\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\n\ncitation(\"infer\")\n\nTo cite package 'infer' in publications use:\n\n  Couch et al., (2021). infer: An R package for tidyverse-friendly\n  statistical inference. Journal of Open Source Software, 6(65), 3661,\n  https://doi.org/10.21105/joss.03661\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {{infer}: An {R} package for tidyverse-friendly statistical inference},\n    author = {Simon P. Couch and Andrew P. Bray and Chester Ismay and Evgeni Chasnovski and Benjamin S. Baumer and Mine Çetinkaya-Rundel},\n    journal = {Journal of Open Source Software},\n    year = {2021},\n    volume = {6},\n    number = {65},\n    pages = {3661},\n    doi = {10.21105/joss.03661},\n  }"
  },
  {
    "objectID": "exercises/11_article_exercise.html#create-appropriate-tables-and-or-figures",
    "href": "exercises/11_article_exercise.html#create-appropriate-tables-and-or-figures",
    "title": "Article exercise",
    "section": "",
    "text": "Use summarize() and ggplot() to create a set of tables/figures that illustrate each hypothesis. You should create at least 4 tables/figures (one for each topic). You will refer to these tables/figures in your results section. Ensure that any plot clearly shows the variables in questions and that the axis are clearly labelled.\nAnytime you report a value in a table, try and also provide 95% confidence intervals (if approportiate).\n\n\n\n\n\n\nggplot2 quick guide\n\n\n\n\n\n\n1my_data |&gt;\n2  ggplot(mapping = aes(x = _____, y = _____, colour = _____, fill = _____)) +\n3  geom_____() +\n4  labs(x = _____, y = _____, title = _____) +\n5  theme______()\n\n\n1\n\nYour dataset.\n\n2\n\nIdentify which variables should be mapped to which features of the plot.\n\n3\n\nIdentify what geometries you will use. More than one is allowed!\n\n4\n\nGive your plot clear axis labels.\n\n5\n\nChange the theme if you wish.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown tables quick guide\n\n\n\n\n\nIf you would like your tables to format nicely when you “knit” your RMarkdown file, you can pipe them into the knitr function called kable(). You need to either load the knitr package first, or you can simply write knitr::kable(). This syntax allows R to access a single function within a package, without loading the whole package.\nWhen the document is knitted, they will look nice:\n\niris |&gt; \n  group_by(Species) |&gt;\n  summarise(\n    n = n(),\n    mean_sepal_length = mean(Sepal.Length),\n    mean_petal_length = mean(Petal.Length)\n    ) |&gt;\n  knitr::kable()\n\n\n\n\nSpecies\nn\nmean_sepal_length\nmean_petal_length\n\n\n\n\nsetosa\n50\n5.006\n1.462\n\n\nversicolor\n50\n5.936\n4.260\n\n\nvirginica\n50\n6.588\n5.552"
  },
  {
    "objectID": "exercises/11_article_exercise.html#perform-the-statistical-analysis",
    "href": "exercises/11_article_exercise.html#perform-the-statistical-analysis",
    "title": "Article exercise",
    "section": "",
    "text": "Use what you have learned during the course so far to conduct the analysis you have described. Make use of the infer package. Use examples from previous exercises, or from the infer set of examples. Record the outcome of each test in the RMarkdown document."
  },
  {
    "objectID": "exercises/11_article_exercise.html#write-a-results-section",
    "href": "exercises/11_article_exercise.html#write-a-results-section",
    "title": "Article exercise",
    "section": "",
    "text": "A results section is where you report your findings to all the hypotheses laid out in the introduction and methods. You have already described your statistical analysis in the methods section, so there is no need to go into great detail here. Importantly, in a paper with separate results and discussion sections, you should not discuss your findings in the results section, only report them. Any time you report a result, you should back it up with a statistic, and a relevant figure. A helpful two part structure you can follow for each result is the following:\n\nReport the overall result in plain language. If the reader reads only this sentence, they should get the whole picture in broad terms.\n\n\nPerceived population density during development had X effect on reproductive investment.\n\n\nReport the result in more specific terms. Make reference to the source of your results, such as statistical tests, tables and figures. You may have several sentences like this for each overall result.\n\n\nAccessory gland mass [did/did not] differ significantly between males reared in high or low densities (difference in means test, diff = X, $p = Y, figure Z)."
  },
  {
    "objectID": "exercises/11_article_exercise.html#give-the-paper-a-title",
    "href": "exercises/11_article_exercise.html#give-the-paper-a-title",
    "title": "Article exercise",
    "section": "",
    "text": "Often the title of a paper will summarise the results in a single line. Can you think of a good title that summarises what you found?"
  },
  {
    "objectID": "exercises/11_article_exercise.html#end-of-the-exercise",
    "href": "exercises/11_article_exercise.html#end-of-the-exercise",
    "title": "Article exercise",
    "section": "",
    "text": "Once you are finished with the exercise (or at the end of the exercise session if you have not finished), submit your work to the Canvas assignment. You will not be graded, and instead I will provide broad feedback to the class."
  },
  {
    "objectID": "exercises/09_correlation.html",
    "href": "exercises/09_correlation.html",
    "title": "Correlation and linear regression I",
    "section": "",
    "text": "Each time we start a new exercise, you should:\n\nMake a new folder in your course folder for the exercise (e.g. biob11/exercise_9)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\nPlease ensure you have followed the step above before you start!"
  },
  {
    "objectID": "exercises/09_correlation.html#analysis",
    "href": "exercises/09_correlation.html#analysis",
    "title": "Correlation and linear regression I",
    "section": "Analysis",
    "text": "Analysis\n\nGeneral\n\nIn your opinion, what (statistical) population are the researchers trying to make inferences about?\n\n\n\nData handling and plotting\n\nEnsure you have loaded the tidyverse and infer packages.\nImport the dataset using read_csv().\nCheck the data for mistakes.\nMake illustrative plot(s) of the key variables to address “Bergmann’s rule” in the dataset using ggplot().\n\n\n\nDoes Minuca pugnax follow Bergmann’s rule\n\nState the null and alternative hypothesis.\nWhat method and test statistic(s) will you use? Why?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nI think this is one of the examples where you could argue for either using a correlation analysis or using a regression analysis. It depends on if you think it would be meaningful to make the statement: “For each degree increase in latitude, Minuca pugnax will be on average X bigger”. If yes, and the relationship appears to be linear, then use linear regression. If you would feel safer saying “There is a positive/negative correlation between Minuca pugnax size and latitude”, and not ascribing causality or a strict rule, then you should use a correlation approach. You could also answer the question in a completely different way, by testing if crabs from the highest latitude differ from those at the lowest, for example.\n\n\n\n\nCalculate the observed statistic(s).\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\nCorrelation:\n\nobserved_statistic &lt;-\n1  ______ |&gt;\n2  specify(______ ~ ______) |&gt;\n3  calculate(stat = \"______\")\n\n4observed_statistic\n\n\n1\n\nThe name of the dataset.\n\n2\n\nA formula in the form of dependant ~ independant\n\n3\n\nCalculate the observed statistic.\n\n4\n\nPrint the observe statistic to the console.\n\n\n\n\nLinear regression:\n\nobserved_fit &lt;-\n1  ______ |&gt;\n2  specify(______ ~ ______) |&gt;\n3  fit()\n\n4observed_fit\n\n\n1\n\nThe name of the dataset.\n\n2\n\nA formula in the form of dependant ~ independant\n\n3\n\nFit the linear model.\n\n4\n\nPrint the observe fit to the console.\n\n\n\n\n\n\n\n\nCalculate 95% confidence intervals for your observed statistic(s).\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\nCorrelation:\n\n______ &lt;-\n1  ______ |&gt;\n2  specify(______ ~ ______) |&gt;\n3  generate(reps = ______, type = \"______\") |&gt;\n4  calculate(stat = \"______\")\n\n5percentile_ci &lt;- get_ci(______, type = \"______\", level = ______)\n\n6percentile_ci\n\n\n1\n\nThe name of the dataset.\n\n2\n\nA formula in the form of dependant ~ independant (order does not matter for a correlation)\n\n3\n\nDecide how you will generate a datasets to use in your sampling distribution.\n\n4\n\nCalculate the statistic for each sample to make a sampling distribution.\n\n5\n\nUse your sampling distribution object to calculate the confidence internals\n\n6\n\nPrint the CI\n\n\n\n\nLinear regression:\n\n______ &lt;-\n1  ______ |&gt;\n2  specify(______ ~ ______) |&gt;\n3  generate(reps = ______, type = \"______\") |&gt;\n4  fit()\n\n5percentile_ci &lt;- get_ci(______, point_estimate = ______, level = ______)\n\n6percentile_ci\n\n\n1\n\nThe name of the dataset.\n\n2\n\nA formula in the form of dependant ~ independant\n\n3\n\nDecide how you will generate a datasets to use in your sampling distribution.\n\n4\n\nFit the linear regression to each sample to get a sampling distribution.\n\n5\n\nUse your sampling distribution object and your observed statistics to calculate the confidence internals\n\n6\n\nPrint the CI\n\n\n\n\n\n\n\n\nGenerate a null distribution. Describe why your chosen method is appropriate.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\nCorrelation:\n\n______ &lt;-\n1  ______ |&gt;\n2  specify(______ ~ ______) |&gt;\n3  hypothesize(null = \"______\") |&gt;\n4  generate(reps = ______, type = \"______\") |&gt;\n5  calculate(stat = \"______\")\n\n\n1\n\nThe name of the dataset.\n\n2\n\nA formula in the form of dependant ~ independant (order does not matter for a correlation)\n\n3\n\nWhat is your null hypothesis?\n\n4\n\nDecide how you will generate a datasets under your null hypothesis to use in your null distribution.\n\n5\n\nCalculate the statistic for each sample to make a sampling distribution.\n\n\n\n\nLinear regression:\n\n______ &lt;-\n1  ______ |&gt;\n2  specify(______ ~ ______) |&gt;\n3  hypothesize(null = \"______\") |&gt;\n4  generate(reps = ______, type = \"______\") |&gt;\n5  fit()\n\n\n1\n\nThe name of the dataset.\n\n2\n\nA formula in the form of dependant ~ independant\n\n3\n\nWhat is your null hypothesis?\n\n4\n\nDecide how you will generate a datasets under your null hypothesis to use in your null distribution.\n\n5\n\nFit the linear regression to each sample to get a sampling distribution.\n\n\n\n\n\n\n\n\nPlot the null distribution and the observed statistic. Calculate a p-value(s) for your null hypothesis.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\n______ |&gt;\n1  visualise() +\n2  shade_p_value(obs_stat = ______, direction = \"______\") +\n3  labs(x = \"______\")\n\n4_____ |&gt;\n  get_p_value(obs_stat = ______, direction = \"______\")\n\n\n1\n\nPipe your null distribution object into visualise().\n\n2\n\nPlot your observed statistic(s), and specify that the direction of your hypothesis.\n\n3\n\nYou can change the axis labels to make the plot more clear.\n\n4\n\nYour null distribution.\n\n\n\n\n\n\n\n\nWrite a small statement that summarises your statistical methods and findings. You should:\n\nState clearly the research question, and what your hypotheses were. Explain why these hypotheses answer your research question.\nExplain your choice of test statistic/method. Relate this to your hypotheses and question.\nState your observed statistics(s) and confidence intervals. Explain what these mean. Refer to a plot you made that shows the data.\nState the outcome of your hypothesis test (quoting test statisitc(s) and p-values). Interpret this result, in both terms of your statistical hypothesis, but also the broad research question."
  },
  {
    "objectID": "exercises/07_anova.html",
    "href": "exercises/07_anova.html",
    "title": "Analysis of variance (ANOVA)",
    "section": "",
    "text": "Each time we start a new exercise, you should:\n\nMake a new folder in your course folder for the exercise (e.g. biob11/exercise_7)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\nPlease ensure you have followed the step above before you start!"
  },
  {
    "objectID": "exercises/07_anova.html#analysis",
    "href": "exercises/07_anova.html#analysis",
    "title": "Analysis of variance (ANOVA)",
    "section": "Analysis",
    "text": "Analysis\nWhile working on your analysis, answer the questions below:\n\nGeneral\n\nWhat (statistical) population are the researchers trying to make inferences about?\n\n\n\nData handling and plotting\n\nLoad the tidyverse and infer packages.\nImport the dataset using read_csv().\nWhat sort of variables are dry_mass_g and treatment?\nCheck the data for mistakes.\nMake an illustrative plot of the dataset.\n\n\n\nDescriptive statistics\nReport the following statistics:\n\nThe overall mean of dry_mass_g.\nThe mean of dry_mass_g for each treatment group.\nThe standard deviation of dry_mass_g for each treatment group.\n\n\n\nIs there a difference in means between the groups?\nThis sort of analysis is called an ANOVA (ANalysis Of VAriance). Specifically, it is a one-way ANOVA, as we are interested in the effect of one categorical variable on a continuous variable.\n\nState the null and alternative hypothesis.\nWhat is the test statistic we use in an ANOVA?\nCalculate the observed test statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nobserved_stat &lt;-\n1  ______ |&gt;\n2  specify(response = ______, explanatory = ______) |&gt;\n3  calculate(stat = \"______\")\n\n4observed_stat\n\n\n1\n\nThe name of the dataset.\n\n2\n\nSpecify which is your response and explanatory variable.\n\n3\n\nCalculate the observed statistic.\n\n4\n\nPrint the observe statistic to the console.\n\n\n\n\n\n\n\n\nTo generate a null distribution, we can use a permutation approach, where we shuffle the assigned categories and calculate our statistic many many times. Generate a null distribution.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist &lt;-\n1  ______ |&gt;\n2  specify(response = ______, explanatory = ______) |&gt;\n3  hypothesize(null = \"independence\") |&gt;\n4  generate(reps = 10000, type = \"permute\") |&gt;\n5  calculate(stat = \"______\")\n\n\n1\n\nThe name of the dataset.\n\n2\n\nSpecify which is your response and explanatory variable.\n\n3\n\nOur hypothesis is that our response variable is independant of our explanatory variable.\n\n4\n\nSimulate data using permuations. This may take a few seconds to minutes depending on your computer.\n\n5\n\nFrom each of our simulated permutation samples, calculate the test statistic.\n\n\n\n\n\n\n\n\nPlot the null distribution and the observed statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n1  visualise(bins = 15) +\n2  shade_p_value(obs_stat = observed_stat, direction = \"greater\") +\n3  labs(x = \"______ statistic\")\n\n\n1\n\nPipe your null_dist object into visualise(). You can change the number of bins if you wish.\n\n2\n\nPlot your observed_stat, and specify that the direction should be greater. Our statistic is a ratio, so is naturally bounded at 0.\n\n3\n\nYou can change the axis labels to make the plot more clear.\n\n\n\n\n\n\n\n\nUse your observed statistic and your null distribution to calculate a p-value.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_stat, direction = \"greater\")\n\n\n\n\n\nWhat are your conclusions? State them both clearly in terms of the null hypothesis and as if you were describing them to someone who does not know about statistics."
  },
  {
    "objectID": "exercises/07_anova.html#post-hoc-analysis",
    "href": "exercises/07_anova.html#post-hoc-analysis",
    "title": "Analysis of variance (ANOVA)",
    "section": "Post-hoc analysis",
    "text": "Post-hoc analysis\nYou might suspect that one particular treatment group is causing your ANOVA result. As the ANOVA does not let you say which group(s) are different from the global mean, there is often the need for a post-hoc (Latin for “after this”) analysis.\nA post-hoc analysis are tests you do after you have seen your data (and often some results). It is important to differentiate this analysis from your original one, as you did not plan to do it and (remember from the slides) the more tests you do, the more likely you are to find a low p-value by chance alone. As such unethical researchers may be tempted to propose additional tests as if they were part of the original plan (HARKing) and to keep doing analyses until they find a low p-value (p-hacking or data-dredging). Both of these practises have likely contributed to the replication crisis in many field, including biology.\nIn this case, we will perform a post-hoc analysis of the difference of means between one of the treatments and the control. We want to know if it has had a statistically significant effect on the growth of the crops.\n\nFilter the dataset\n\nUse filter to produce another dataset that only has the treatment groups you are interested in.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\n1______ &lt;-\n2  ______ |&gt;\n3  filter(treatment == \"control\" | treatment == \"______\")\n\n\n1\n\nThe new name of your filtered dataset\n\n2\n\nThe name of your original dataset\n\n3\n\nWe only keep rows where treatment is equal to \"control\" OR | where treatment is equal to \"______\"\n\n\n\n\n\n\n\n\n\nPerform the post-hoc analysis\n\nState clearly the null and alternative hypotheses for this post-hoc analysis.\nUsing your new dataset, calculate the observed statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nobserved_stat &lt;-\n1  ______ |&gt;\n2  specify(response = ______, explanatory = ______) |&gt;\n3  calculate(stat = \"______\", order = c(\"______\", \"control\"))\n\n4observed_stat\n\n\n1\n\nThe name of your new filtered dataset.\n\n2\n\nSpecify which is your response and explanatory variable.\n\n3\n\nCalculate the observed statistic, specifiying the order as treatment - control. That way a positive number indicates that the treatment made the crops grow bigger.\n\n4\n\nPrint the observe statistic to the console.\n\n\n\n\n\n\n\n\nGenerate a null distribution.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist &lt;-\n1  ______ |&gt;\n2  specify(response = ______, explanatory = ______) |&gt;\n3  hypothesize(null = \"independence\") |&gt;\n4  generate(reps = 10000, type = \"______\") |&gt;\n5  calculate(stat = \"______\")\n\n\n1\n\nThe name of the new dataset.\n\n2\n\nSpecify which is your response and explanatory variable.\n\n3\n\nOur hypothesis is that our response variable is independant of our explanatory variable.\n\n4\n\nWhat simulation approach should you use here?\n\n5\n\nFrom each of our simulated samples, calculate the test statistic.\n\n\n\n\n\n\n\n\nPlot the null distribution and the observed statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n1  visualise(bins = 15) +\n2  shade_p_value(obs_stat = observed_stat, direction = \"_____\") +\n3  labs(x = \"______\")\n\n\n1\n\nPipe your null_dist object into visualise(). You can change the number of bins if you wish.\n\n2\n\nPlot your observed_stat, and specify that the direction of the hypothesis?\n\n3\n\nYou can change the axis labels to make the plot more clear.\n\n\n\n\n\n\n\n\nUse your observed statistic and your null distribution to calculate a p-value.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_stat, direction = \"______\")\n\n\n\n\n\nWhat are your conclusions of the post-hoc analysis?\n\n\n\nCorrecting p-values for multiple testing\nIf you had gone on to perform more post-hoc tests (like testing other treatments against the control), you might want to perform a correction to your p-values that recognises that the more tests you do, the more likely you are to find a low p-value by chance.\nOne way to do this is the Bonferroni correction. This simply devides your \\(\\alpha\\) value (the p-value at which you deem a test to be significant) by the number of tests you did. So if we compared each fertilizer to the control (3 comparisons, 3 tests) we should use an \\(\\alpha\\) value of \\(\\frac{0.05}{3}=0.0166\\) (assuming our prior \\(\\alpha=0.05\\)). You can achieve the same result by keeping \\(\\alpha=0.05\\) and multiplying all your p-values by the number of tests you performed."
  },
  {
    "objectID": "exercises/07_anova.html#experimental-design",
    "href": "exercises/07_anova.html#experimental-design",
    "title": "Analysis of variance (ANOVA)",
    "section": "Experimental design",
    "text": "Experimental design\n\nRead again the description of the experiment and look at Figure 1.\n\nIdentify one aspect of their experimental design which will have helped them collect unbiased data.\nSuggest one way in which the researchers could improve their experimental design?"
  },
  {
    "objectID": "exercises/05_uncertainty.html",
    "href": "exercises/05_uncertainty.html",
    "title": "Estimation, uncertainty and error",
    "section": "",
    "text": "Each time we start a new exercise, you should:\n\nMake a new folder in your course folder for the exercise (e.g. biob11/exercise_5)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\nWe are now ready to start."
  },
  {
    "objectID": "exercises/05_uncertainty.html#collect-a-sample",
    "href": "exercises/05_uncertainty.html#collect-a-sample",
    "title": "Estimation, uncertainty and error",
    "section": "Collect a sample",
    "text": "Collect a sample\nSticking with the height of trees example, each student will virtually sample 100 trees at random from the forest. I (Iain) have data on every tree in the forest (because I simulated it). As such I know the true properties of the forest (usually we can never know this information). Each of you will work with a different sample, and we will see how good an estimate of the true properties of the forest you can get from your sample.\nRun the bit of code below in your browser. It will assign you a sample to work with. Use the link it outputs to download a .csv file as you did in the previous exercise."
  },
  {
    "objectID": "exercises/05_uncertainty.html#calculate-observed-statistics",
    "href": "exercises/05_uncertainty.html#calculate-observed-statistics",
    "title": "Estimation, uncertainty and error",
    "section": "Calculate observed statistics",
    "text": "Calculate observed statistics\nWe want to use our sample to estimate the mean and standard deviation of the height of trees tree_height_mm in the forest. You can do that any way you want, as long as you end up with two objects, one that contains the mean and one that contains the standard deviation. Use code from previous exercises to help you.\nOnce you have calculated them, write them on the board.\nAnswer the following questions:\n\nWhat does each of the following statistics describe:\n\nThe arithmetic mean\nThe standard deviation\n\nWhat are the units of each of the following statistics (in this example):\n\nThe arithmetic mean\nThe standard deviation"
  },
  {
    "objectID": "exercises/05_uncertainty.html#estimate-the-uncertainty",
    "href": "exercises/05_uncertainty.html#estimate-the-uncertainty",
    "title": "Estimation, uncertainty and error",
    "section": "Estimate the uncertainty",
    "text": "Estimate the uncertainty\nThe next step is to calculate a measure of uncertainty in our observed statistics. We only took a single sample of \\(n = 100\\) out of a \\(10000\\) tree forest. Because of this, our observed statistics may not be exactly equal to the true population parameters1. In other words, if we were to go back to the forest and measure the heights of another random sample of trees (like your neighbour has done), the observed test statistics would probably be slightly different. We want to provide some estimate of the uncertainty in the observed statistics in our sample that reflects this.\nTo do that, we can use a bootstrap procedure. This is an important concept to understand, and it can be a little counter-intuative, so it may take a few reads for it to click. After all, we are generating many “samples” from a single sample! From Section 8.2 of Chester et al. (2025):\n\nIn 1979, Brad Efron published an article introducing a method called the bootstrap (Efron 1979) that is next summarized. A random sample of size \\(n\\) is taken from the population. This sample is used to find another sample, with replacement, also of size \\(n\\). This is called resampling with replacement and the resulting sample is called a bootstrap sample. For example, if the original sample is \\(\\{4,2,5,4,1,3,7,4,6,1\\}\\), one particular bootstrap sample could be \\(\\{6, 4, 7, 4, 2, 7, 2, 5, 4, 1\\}.\\) Observe that the number 7 appears once in the original sample, but twice in the bootstrap sample; similarly, the number 3 in the original sample does not appear in the bootstrap sample. This is not uncommon for a bootstrap sample, some of the numbers in the original sample are repeated and others are not included.\n\n\nThe basic idea of the bootstrap is to gain a large number of bootstrap samples, all drawn from the same original sample. Then, we use all these bootstrap samples to find estimates of population parameters, standard errors, or even the density curve of the population. Using them we can construct confidence intervals, perform hypothesis testing, and other inferential methods.\n\n\nThis method takes advantage of the large number of bootstrap samples that can be determined. In several respects, this exercise is not different from the sampling distribution explained in Chapter 7. The only difference, albeit an important one, is that we are not sampling from the population, we are sampling from the original sample. How many different bootstrap samples could we get from a single sample? A very large number, actually. If the original sample has 10 numbers, as the one shown above, each possible bootstrap sample of size 10 is determined by sampling 10 times with replacement, so the total number of bootstrap samples is \\(10^{10}\\) or 10 billion different bootstrap samples. If the original sample has 20 numbers, the number of bootstrap samples is \\(20^{20}\\), a number greater than the total number of stars in the universe. Even with modern powerful computers, it would be an onerous task to calculate every possible bootstrap sample. Instead, a thousand or so bootstrap samples are retrieved, similar to the simulations performed in Chapter @ref(sampling), and this number is often large enough to provide useful results.\n\n\nSince Efron (Efron 1979) proposed the bootstrap, the statistical community embraced this method. During the 1980s and 1990s, many theoretical and empirical results were presented showing the strength of bootstrap methods. As an illustration, Efron (Efron 1979), Hall (Hall1986?), Efron and Tibshirani (1986), and Hall (1988) showed that bootstrapping was at least as good if not better than existent methods, when the goal was to estimate the standard error of an estimator or find the confidence intervals of a parameter. Modifications were proposed to improve the algorithm in situations where the basic method was not producing accurate results. With the continuous improvement of computing power and speed, and the advantages of having ready-to-use statistical software for its implementation, the use of the bootstrap has become more and more popular in many fields.\n\n\nAs an illustration, if we are interested in the mean of the population and we have collected one random sample, we can gain a large number of bootstrap samples from this original sample, use them to calculate sample means, order the sample means from smallest to largest, and choose the interval that contains the middle 95% of these sample means. This will be the simplest way to find a confidence interval based on the bootstrap. In the next few subsections, we explore how to incorporate this and similar methods to construct confidence intervals.\n\n\nGenerating bootstrap samples\nWe can use the infer package to generate bootstrap samples. As when we were doing hypothesis testing, we specify() the variable we are interested in, then generate() the bootstrap replicates (note as we are not testing a hypothesis, we do not need a hypothesize() step).\nThe first argument of generate() is the number of reps (replicates), which is the number of (in this case) bootstrap samples we would like to generate(). You should set this value to at least 1000, but as you all have fairly modern computers, values such as 10000 will probably run in less than a second. Using higher values has diminishing returns, and will make plotting take a lot longer!\nThe second argument of generate() is the type of simulation. Recall that when we performed a hypothesis test on the difference of two means, we used type = \"permute\" to shuffle our explanatory variable in order to produce a null distribution. In this case, we want to do a type = \"bootstrap\" simulation.\nUse the code below to generate() bootstrap samples, then answer the questions.\n\n______ |&gt; \n  specify(response = ______,) |&gt; \n  generate(reps = ______, type = ______)\n\n\nWhat real world process is the bootstrap procedure simulating?\nWhy does the output of the code above have the number of rows that it does?\nIn theory, how many unique bootstrap samples could you generate from your original sample (if you had infinite time and computing power)?\n\n\n\nCalculating bootstrap sample statistics\nAfter we generate() our bootstrap samples, we want to summarize each of them by calculating the statistics we are interested in. We do that as we did before, with the calculate() function. Add a pipe |&gt;, then calculate() the statistics we are interested in.2 Save each set of bootstrap simulated statistics as seperate objects.\n\n\nVisualize the bootstrap sampling distribution\nUse visualize() to quickly produce plots of your two bootstrap sampling distribution. Note that these plots are just ggplot() objects so, for example, you can use + to add things like labs(x = \"My statistic\") or change the theme_. visualize() is simply a shortcut for writing:\n\n1bootstrap_statistics |&gt;\nggplot(aes(x = stat)) +\ngeom_histogram()\n\n\n1\n\nWhere bootstrap_statistics is the data frame of calculated statistics from your bootstrap simulations.\n\n\n\n\nAnswer the following questions:\n\nWhat do these distributions show? How would you describe this distribution to someone who does not know what “bootstrapping” is?\nDescribe the shape of each distribution? Are they the same? Why?\nWhere do your observed statistics lie on these distributions?\n\n\n\nConfidence intervals\nA confidence interval quantifies the effect of sampling error on obtaining an estimate. A strict interpretation of a confidence interval is:\nIf we repeated our experiment many times and calculated a X% CI each time, the X% CI’s would include the “true” value X% of the time.\nA less strict definition could also be that CI’s provide a plausible range for the true value we aim to estimate.\nConfidence intervals are most helpful when stated alongside your observed statistic. For example, you might write that the average tree height was 2.46 m (95% CI: 1.92 - 2.81 m). A large confidence interval implies that there is a high influence of sampling error. Conversly, a small confidence interval implies that there is a low influence of sampling error.\nAnswer the following questions:\n\nFrom this definition, can you think of two properties of our sample that might affect the confidence interval?\n\n\n\nCalculating confidence intervals\nThere are a few ways we can calculate a confidence interval. The first way we will cover is (almost) universal (you can apply them to any test statistic, with a few caveats) and the last relies on a special property of the sampling distribution of means. Just know that there are many ways to do this, but we do not have the time to go through the theory that justifies some of the more complicated options.\n\nThe percentile method\nFrom Chester et al. (2025):\n\nThe percentile method for constructing 95% confidence intervals sets the lower endpoint of the confidence interval at the 2.5th percentile of the bootstrap sampling distribution and similarly sets the upper endpoint at the 97.5th percentile. The resulting interval captures the middle 95% of the values of the bootstrap sampling distribution.\n\nTo calculate the percentile confidence interval, you should pipe |&gt; your bootstrap sampling distribution into the get_confidence_interval() function, with type = \"percentile\". Use the level = argument to set your confidence interval (e.g. 0.95 for a 95% CI).\n\n______ |&gt; \n  get_confidence_interval(level = ______, type = \"percentile\")\n\nSave these confidence intervals as an object, as we will need to use them in a moment.\nTo visualize these confidence intervals on our bootstrap sampling distribution, use the same visualize() code as before, and add:\n\n1+ shade_confidence_interval(endpoints = ______)\n\n\n1\n\nReplace ______ with your percentile confidence intervals\n\n\n\n\nWrite your 95% percentile CI on the board next to your observed test statistics\n\n\nThe standard error method\nRecall that the definition of the standard error (of the mean) is the standard deviation of the sampling distribution of means. That is, if we were to keep taking new samples from our population and calculating means of those samples, the standard deviation of the resulting distribution of means is the standard error. Sound familiar? This is exactly what we have simulated using our bootstrap simulations (for the mean at least)!\nThe sampling distribution of means has special properties. From Chester et al. (2025):\n\nA fascinating result in statistics is that, when retrieving random samples from any population, the corresponding sample means follow a typical behavior: their histogram is bell-shaped and has very unique features. This is true regardless of the distribution of the population values and forms the basis of what we know as the Central Limit Theorem.\n\nThis distribution is called the normal distribution. We will talk more about it during a lecture, but know now that one feature of this distribution is that to capture the middle 95% of it, we can use the following formula: \\[\n\\left(\\overline{x} - 1.96 \\cdot SE_{\\text{boot}}, \\quad \\overline{x} + 1.96 \\cdot SE_{\\text{boot}}\\right)\n\\]\nIn words, the upper 95% CI can be calculated by multiplying the standard error (which in our example, is the standard deviation of our bootstrap sampling distribution) by 1.96 and then adding the mean. The lower 95% CI is calculated in a similar fashion, but substracted from the mean.\nNote that only works for the sampling distribution of means\nTo calculate this, we can use the same get_confidence_interval() function, but this time we also need to support a point_estimate = (our observed mean) and change the type = \"se\".\n\n______ |&gt;\n  get_confidence_interval(type = \"se\", point_estimate = ______, level = ______)\n\nAs you did before, save this as an object, and visualize() it.\nAnswer the following questions:\n\nHow do your confidence intervals for the mean compare with the percentile and the standard error method?\nWhy can we not use 100% confidence intervals?\n\n\n\n\nPlotting uncertainty on figures\nError bars are a common way to visualize uncertainty in observed statistics. In ggplot2, you can add error bars to your plots using the geom_errorbar() function. This function requires you to specify the aesthetics for the minimum and maximum values of the error bars, typically using ymin and ymax. Your confidence interval objects contain the information needed.\nHere are some examples of how you might visualise your 95% CI of the mean on a figure. In this example\n\n1summary_data &lt;-\n  observed_mean |&gt; \n  bind_cols(percentile_ci) |&gt;\n2  rename(tree_height_m = stat)\n\n3tree_data |&gt;\n4  ggplot(aes(y = tree_height_m, x = \"Sample 1\")) +\n  geom_jitter(width = 0.05, alpha = 0.3) +\n5  geom_pointrange(data = summary_data, aes(ymin = lower_ci, ymax = upper_ci), colour = \"red\")\n\n\n1\n\nI first make a new dataframe, by combining my observed mean and my confidence interval dataframes with bind_cols()\n\n2\n\nTo make sure ggplot knows that I want the mean value to be on the same scale as the normal data, I rename it to have the same name.\n\n3\n\ntree_data is my original sample dataframe.\n\n4\n\nI write x = \"Sample 1\", as I want to show this using a geom (geom_jitter) that requires and x and a y variable. x = \"Sample 1\" acts as a “dummy variable” (it has no meaning, just here for plotting).\n\n5\n\ngeom_pointrange() plots both a point and a range. Note that you can provide different data frames to different geom_ if you want, like I did here.\n\n\n\n\n\n\n\n\n\n\n\nIn general, if you are unsure how to plot something in ggplot2(), a search engine is your friend. You will find countless examples. The ggplot2 cheatsheet is also a great place to look.\nOnce you have made your figure, you should write a figure caption explaining clearly what your figure show, including what any error bars are representing (very important!)."
  },
  {
    "objectID": "exercises/05_uncertainty.html#state-your-hypotheses",
    "href": "exercises/05_uncertainty.html#state-your-hypotheses",
    "title": "Estimation, uncertainty and error",
    "section": "State your hypotheses",
    "text": "State your hypotheses\nHere, convert the research question into a null hypothesis and an alternative hypothesis. State these clearly. Is there a direction to your alternative hypothesis?"
  },
  {
    "objectID": "exercises/05_uncertainty.html#plot-the-data",
    "href": "exercises/05_uncertainty.html#plot-the-data",
    "title": "Estimation, uncertainty and error",
    "section": "Plot the data",
    "text": "Plot the data\nMake an illustrative plot that reflects the research question. Ensure that the axis have clear labels."
  },
  {
    "objectID": "exercises/05_uncertainty.html#calculate-the-observed-statistic",
    "href": "exercises/05_uncertainty.html#calculate-the-observed-statistic",
    "title": "Estimation, uncertainty and error",
    "section": "Calculate the observed statistic",
    "text": "Calculate the observed statistic\nBefore you click the box below, try to decide yourself what the observed statistic should be in this case. Remember, a statistic is just any property we could calculate from a sample.\n\n\n\n\n\n\nHow to calculate the observed statistic\n\n\n\n\n\n\n3______ &lt;-\n  ______ |&gt;\n1   specify(response = ______, success = \"______\") |&gt;\n2   calculate(stat = \"______\")\n\n\n1\n\nWhen we use a proportion as our statistic, we use terminology that comes from thinking about a proportion as a probability. For example, if you flipped a coin 100 times, and recorded the proportion of heads (which we would expect to be about 0.5), then the number of “successes” in our “trial” would be 50. As such, we would say that the probability of flipping a coin and getting a “success” (heads in this case) is 0.5. For success = \"______\", you should provide the value in your response = variable that would indicate the tree is ready for harvest.\n\n2\n\nUse the helpfile (?calculate) to figure out what you should write to get a proportion.\n\n3\n\nAssign this to a new object, as we will use it later."
  },
  {
    "objectID": "exercises/05_uncertainty.html#calculating-a-confidence-interval",
    "href": "exercises/05_uncertainty.html#calculating-a-confidence-interval",
    "title": "Estimation, uncertainty and error",
    "section": "Calculating a confidence interval",
    "text": "Calculating a confidence interval\nSince we have just calculated them, let’s also calculate a confidence interval here for the observed statistic. Note that this is NOT a hypothesis test (although it gives us information that might affect our predicted outcomes of a hypothesis test). We are calculating this to show our uncertainty in our observed statistic due to sampling error.\nAdapt the code we just used to calculate the statistic, and the code we used before to generate bootstrap samples to calculate a 95% CI for your observed statistics."
  },
  {
    "objectID": "exercises/05_uncertainty.html#adding-the-confidence-interval-to-your-plot",
    "href": "exercises/05_uncertainty.html#adding-the-confidence-interval-to-your-plot",
    "title": "Estimation, uncertainty and error",
    "section": "Adding the confidence interval to your plot",
    "text": "Adding the confidence interval to your plot\nAdd the confidence interval to the plot you made before, using the geom_errorbar() (verticle error bars) or geom_errorbarh() (horizontal error bars). Try to use the example above and resources online before asking for help.\nNOTE: Since you might have shown both the proportion of “succeses” and “failures” on your original plot, you may need to calculate a confidence interval for the “failures”. You do this using the same code as above, but you would change you success = argument to the other option in your response = variable."
  },
  {
    "objectID": "exercises/05_uncertainty.html#test-your-hypothesis",
    "href": "exercises/05_uncertainty.html#test-your-hypothesis",
    "title": "Estimation, uncertainty and error",
    "section": "Test your hypothesis",
    "text": "Test your hypothesis\nSimilar to how we did in Exercise 4, we want to simulate a null distribution. We do that by imagining a world in which our null hypothesis is TRUE, and simulate data compatible with that world. Try to use the code from that exercise, in combination with some of the code we used to calculate our observed statistic today. You might need to look at the helpfiles for hypothesize() to figure out what arguments you need to use. You can also use the infer set of examples as a guide.\nAs you have done before, visualize() both your null distribution and your observed statistic. In addition calculate a p-value."
  },
  {
    "objectID": "exercises/05_uncertainty.html#report-your-findings",
    "href": "exercises/05_uncertainty.html#report-your-findings",
    "title": "Estimation, uncertainty and error",
    "section": "Report your findings",
    "text": "Report your findings\nWrite a paragraph where you decribe your findings, as if you were writing a report for the timber company that owns the forest. Ensure you report your observed statistic with confidence intervals, the outcome of your hypothesis test with p-values, and your conclusions based on your results. Ensure you also phrase your findings in a way in which someone who doesn’t understand the statistics could understand it, and then make a judgement based on it.\nFinally, add your findings to the board."
  },
  {
    "objectID": "exercises/05_uncertainty.html#footnotes",
    "href": "exercises/05_uncertainty.html#footnotes",
    "title": "Estimation, uncertainty and error",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlthough because we took a random sample, and our test statistics are unbiased, the expected value of our sample statistics is the population parameters↩︎\nNote that calculate() will only let you calculate a single statistic at a time↩︎"
  },
  {
    "objectID": "exercises/03_local_r.html",
    "href": "exercises/03_local_r.html",
    "title": "How to install R on your local computer",
    "section": "",
    "text": "In this exercise, we will walk through the steps of installing R and RStudio on your own device. This will give you more freedom when compared with using R via the browser, which has notable limitations."
  },
  {
    "objectID": "exercises/03_local_r.html#why-do-i-need-both",
    "href": "exercises/03_local_r.html#why-do-i-need-both",
    "title": "How to install R on your local computer",
    "section": "Why do I need both?",
    "text": "Why do I need both?\nR is a programming language and software environment specifically designed for statistical computing and graphics.\nRStudio, on the other hand, is an integrated development environment (IDE) for R. It provides a user-friendly interface that makes it easier to write, debug, and visualize R code. RStudio includes features such as syntax highlighting, code completion, and tools for plotting, history, and workspace management. While R can be used on its own, RStudio enhances the user experience and productivity by providing a more organized and efficient workflow.\nTo use a car as a metaphor, R is the engine, and RStudio is the steering wheel, pedals, gear shifter, etc. It gives us a much easier way to interface and work with R.\nSo you need to install both. RStudio does nothing without R (like a car without an engine)."
  },
  {
    "objectID": "exercises/03_local_r.html#how-to-install-r-locally",
    "href": "exercises/03_local_r.html#how-to-install-r-locally",
    "title": "How to install R on your local computer",
    "section": "How to install R locally",
    "text": "How to install R locally\nTo install R on your local device, you need to know what operating system your computer uses. If you are unsure, ask the teacher. Follow the steps in the appropriate section. If you already have R installed, I suggest you check it is up to date. To do that, open R and type R.version. If your major version is 4, then that should be OK for this course.\n\n\n\n\n\n\nWindows\n\n\n\n\n\n\nManual download\n\nGo to the CRAN R Project website.\nClick on the “Download R for Windows” link.\nClick on the “base” link to download the base system.\nClick on the “Download R-x.x.x for Windows” link (where x.x.x is the latest version).\nOnce the download is complete, open the installer and follow the on-screen instructions to complete the installation.\n\n\n\nWinget\nIf you use the package manager winget, you can run the following command to install R:\nwinget install -e --id RProject.R\n\n\nChocolatey\nIf you use the package manager chocolatey, you can run the following command to install R:\nchoco install r.project\n\n\n\n\n\n\n\n\n\n\nmacOS\n\n\n\n\n\n\nManual download\n\nGo to the CRAN R Project website.\nClick on the “Download R for macOS” link.\nClick on the .pkg file link to download the installer for the latest version of R.\n\nIf you have a newer Mac with an Apple silicon CPU (M1, M2, M3, M4, etc), you must download the version specifically for Apple silicon CPU Macs that has arm64 in the package name (e.g. R-4.4.3-arm64.pkg).\nIf you have an older Mac with an Intel CPU (i3, i5, i7, etc), you must download the version specifically for Intel CPU Macs that has x86_64 in the package name (e.g. R-4.4.3-x86_64.pkg).\n\nOnce the download is complete, open the installer and follow the on-screen instructions to complete the installation.\n\n\n\nHomebrew\nIf you use homebrew, you can install R and dependencies via:\nbrew install r\n\n\n\n\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\nDebian\nRun the following commands in your terminal:\nsudo apt update\nsudo apt install r-base r-base-dev\nFor issues, check the dedicated Debian CRAN R Project website.\n\n\nFedora/Redhat\nsudo dnf install R\nFor issues, check the dedicated Fedora CRAN R Project website.\n\n\nUbuntu\n# update indices\nsudo apt update -qq\n# install two helper packages we need\nsudo apt install --no-install-recommends software-properties-common dirmngr\n# add the signing key (by Michael Rutter) for these repos\n# To verify key, run gpg --show-keys /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc \n# Fingerprint: E298A3A825C0D65DFD57CBB651716619E084DAB9\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\n# add the repo from CRAN -- lsb_release adjusts to 'noble' or 'jammy' or ... as needed\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n# install R itself\nsudo apt install --no-install-recommends r-base\nFor issues, check the dedicated Ubuntu CRAN R Project website.\n\n\nOther linux distros\nIf you are using a Linux distro other than the ones above, I trust you probably know enough to figure out how to install R yourself. Just be cautious as to the version of R you are installing. For this course, it needs to be &gt;= 4.0. If you have any issues, let the teacher know.\n\n\n\n\n\n\n\n\n\n\nChromeOS\n\n\n\n\n\nThis is a lot more complicated, sorry.\nYou have three options:\n\nBorrow a windows laptop from the IT department. This would be my first recommendation. But if you want to be able to use your own computer, see the next two options.\nTry and install R locally, using a linux container. This can work, but only reliably for Chromebooks that use an Intel/AMD CPU (not an ARM CPU). Ask the teacher if you are unsure.\nYou use R online instead. This has a few drawbacks depending on the method you use:\n\nYou use webR IDE. This should work for everything we do in the class, but if you accidentally refresh your page or close your browser without saving your work locally, it will be lost.\nYou use Posit Cloud. The free tier should be enough for everything we do here. The downside is you need an internet connection to use it.\nUsing Google Colab. The free tier should again be enough for everything in this class, however the interface is going to be very different.\n\n\n\nInstalling R locally (via a linux container)\nI suggest you follow this guide carefully (it will take some time). Ask the teacher if you are stuck.\n\n\nUsing webR IDE\nThis is a “proof-of-concept” tool, and is not actually intended to be used for real data analysis. However, it is very functional, and we can use it for almost everything in this class. The place where things will be different is when it comes to making Rmarkdown files. This is not supported, but you can still write R scripts with comments, which is fine. You can find it here. However, I would really suggest just using a borrowed laptop over this option.\n\n\nUsing Posit Cloud\nPosit are the company that make RStudio, and they offer a version of it online that works almost identically to the desktop version. All your computations are performed on Posit servers, and with the free plan, you are limited with how much compute time you can use per month. However, the default should be enough for this course. However, I would really suggest just using a borrowed laptop over this option. If you want to use it, you can find it here.\n\n\nGoogle Colab\nColab uses Jupyter to run R code. It is a bit different to the RStudio interface. I personally find that Colab can be very frustrating if you are not a paying user, as you often have to “queue” for a CPU for your code to run on. If you really want to use this (if you are familiar with python/jupyter it might be very intuative), here is a guide to setup R with Colab, and here is a link to Colab itself. However, I would really suggest just using a borrowed laptop over this option.\n\n\n\n\n\n\n\n\n\n\niPadOS\n\n\n\n\n\nThere is no way to run R natively on your device. I strongly suggest you borrow a laptop from the IT department. If you really want to try using your own device, you can access R online. Here are a few options:\n\nUsing webR IDE\nThis should work for everything we do in the class, but if you accidentally refresh your page or close your browser without saving your work locally, it will be lost. It is a “proof-of-concept” tool, and is not actually intended to be used for real data analysis. However, it is very functional, and we can use it for almost everything in this class. The place where things will be different is when it comes to making Rmarkdown files. This is not supported, but you can still write R scripts with comments, which is fine. You can find it here. However, I would really suggest just using a borrowed laptop over this option.\n\n\nUsing Posit Cloud\nPosit are the company that make RStudio, and they offer a version of it online that works almost identically to the desktop version. All your computations are performed on Posit servers, and with the free plan, you are limited with how much compute time you can use per month. However, the default should be enough for this course. However, I would really suggest just using a borrowed laptop over this option. If you want to use it, you can find it here.\n\n\nGoogle Colab\nColab uses Jupyter to run R code. It is a bit different to the RStudio interface. I personally find that Colab can be very frustrating if you are not a paying user, as you often have to “queue” for a CPU for your code to run on. If you really want to use this (if you are familiar with python/jupyter it might be very intuative), here is a guide to setup R with Colab, and here is a link to Colab itself. However, I would really suggest just using a borrowed laptop over this option.\n\n\n\n\n\n\n\n\n\n\nAndroid\n\n\n\n\n\nIn theory you can install R on your device, however you will need to either install a linux container and/or compile everything yourself (complicated and slow). For this reason, I strongly suggest you borrow a laptop from the IT department. If you really want to try using your own device, I will not provide instructions on how to install it locally (it is just too much work), but you can access R online. Here are a few options:\n\nUsing webR IDE\nThis should work for everything we do in the class, but if you accidentally refresh your page or close your browser without saving your work locally, it will be lost. It is a “proof-of-concept” tool, and is not actually intended to be used for real data analysis. However, it is very functional, and we can use it for almost everything in this class. The place where things will be different is when it comes to making Rmarkdown files. This is not supported, but you can still write R scripts with comments, which is fine. You can find it here. However, I would really suggest just using a borrowed laptop over this option.\n\n\nUsing Posit Cloud\nPosit are the company that make RStudio, and they offer a version of it online that works almost identically to the desktop version. All your computations are performed on Posit servers, and with the free plan, you are limited with how much compute time you can use per month. However, the default should be enough for this course. However, I would really suggest just using a borrowed laptop over this option. If you want to use it, you can find it here.\n\n\nGoogle Colab\nColab uses Jupyter to run R code. It is a bit different to the RStudio interface. I personally find that Colab can be very frustrating if you are not a paying user, as you often have to “queue” for a CPU for your code to run on. If you really want to use this (if you are familiar with python/jupyter it might be very intuative), here is a guide to setup R with Colab, and here is a link to Colab itself. However, I would really suggest just using a borrowed laptop over this option."
  },
  {
    "objectID": "exercises/03_local_r.html#how-to-install-rstudio-locally",
    "href": "exercises/03_local_r.html#how-to-install-rstudio-locally",
    "title": "How to install R on your local computer",
    "section": "How to install RStudio locally",
    "text": "How to install RStudio locally\n\n\n\n\n\n\nWindows\n\n\n\n\n\n\nManual download\n\nGo to the RStudio desktop website.\nScroll down and click on the “Download RStudio Desktop for Windows” link (we have already installed R so can skip step 1 in their guide).\nOnce the download is complete, open the installer and follow the on-screen instructions to complete the installation.\n\n\n\nWinget\nIf you use the package manager winget, you can run the following command to install RStudio:\nwinget install --id=Posit.RStudio -e\n\n\nChocolatey\nIf you use the package manager chocolatey, you can run the following command to install R:\nchoco install r.studio\n\n\n\n\n\n\n\n\n\n\nmacOS\n\n\n\n\n\n\nManual download\n\nGo to the RStudio desktop website.\nScroll down and click on the “Download RStudio Desktop for macOS 13+” link (we have already installed R so can skip step 1 in their guide). If you are using a version of macOS that is &lt;13, follow the link on the page to “download a previous version”.\nOnce the download is complete, open the installer and follow the on-screen instructions to complete the installation.\n\n\n\nHomebrew\nIf you use homebrew, you can install R and dependencies via:\nbrew install --cask rstudio\n\n\n\n\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\nManual download\n\nGo to the RStudio desktop website.\nIf your distro is automatically detected, click on the “Download RStudio Desktop for XXX” link (we have already installed R so can skip step 1 in their guide). If your distro is not automatically detected, scroll down to the bottom to find a suitable installer.\nOnce the download is complete, open the installer and follow the on-screen instructions to complete the installation.\n\n\n\nVia various package managers\nThe version of RStudio available via some sources is very out-of-date. For this reason, I suggest either being cautious and checking it is actually up-to-date, or just downloading it from the above link.\n\n\n\n\n\n\n\n\n\n\nChromeOS\n\n\n\n\n\n\nIf you have installed R locally using the guide in the previous section, it will also guide you how to install RStudio.\nIf you are using a web version of R, there is no need to do anything else.\n\n\n\n\n\n\n\n\n\n\niPadOS\n\n\n\n\n\nThere is no way to install RStudio on your device.\n\n\n\n\n\n\n\n\n\nAndroid\n\n\n\n\n\nThere is no (simple) way to install RStudio on your device."
  },
  {
    "objectID": "exercises/03_local_r.html#how-to-use-r-on-your-own-computer",
    "href": "exercises/03_local_r.html#how-to-use-r-on-your-own-computer",
    "title": "How to install R on your local computer",
    "section": "How to use R on your own computer",
    "text": "How to use R on your own computer\nQuite simply, in this course you should never open R, you should always open RStudio. Check that everything has worked by launching RStudio. It should detect your R installation automatically, but if not, a window will open asking you to select it. If R does not appear here, I suggest you restart your computer first.\nYou should be met by a scene that looks like this:\n\n\n\nA screenshot of a new RStudio installation on macOS.\n\n\nYou are now ready for Exercise 4."
  },
  {
    "objectID": "exercises/01_intro_to_r.html",
    "href": "exercises/01_intro_to_r.html",
    "title": "Introduction to R",
    "section": "",
    "text": "R is a powerful, open-source programming language specifically designed for statistical computing, data analysis, and visualization. For biologists, it offers an invaluable toolkit to analyse experimental results, manage large datasets (e.g., genomic or ecological data), and create publication-quality graphs. Unlike point-and-click software, R allows you to automate repetitive tasks, ensuring efficiency and reproducibility in your research. Its flexibility and extensive capabilities make it a staple in almost all fields within biology, both in academia and in industries. A huge reason for this is that R is free to use, and as such has a global community continually developing new tools and resources tailored to scientific research.\n\n\nR can be used in a number of ways. In the next exercise session, we will install R on your computer, along with Rstudio, which is a friendly user interface for R. In this exercise, you will use R in your browser to explore its capabilities.\nNote that once the webpage has loaded, you can edit the code in any of the boxes below (I strongly encourage you to do this!). Press the “Run code” button to run the code you have written. You will learn a lot through experimenting, and you can always reset the code box back to its original state with the “Start over” button."
  },
  {
    "objectID": "exercises/01_intro_to_r.html#how-do-i-use-r",
    "href": "exercises/01_intro_to_r.html#how-do-i-use-r",
    "title": "Introduction to R",
    "section": "",
    "text": "R can be used in a number of ways. In the next exercise session, we will install R on your computer, along with Rstudio, which is a friendly user interface for R. In this exercise, you will use R in your browser to explore its capabilities.\nNote that once the webpage has loaded, you can edit the code in any of the boxes below (I strongly encourage you to do this!). Press the “Run code” button to run the code you have written. You will learn a lot through experimenting, and you can always reset the code box back to its original state with the “Start over” button."
  },
  {
    "objectID": "exercises/01_intro_to_r.html#r-as-a-calculator",
    "href": "exercises/01_intro_to_r.html#r-as-a-calculator",
    "title": "Introduction to R",
    "section": "R as a calculator",
    "text": "R as a calculator\nR, like most programming languages, can perform arithmetic operations. It follows the order of operations used in mathematics. If you want to review that, you can do so in Chapter 1 of Duthie (2025).\nYou can use the following operators to write equations in R:\n\n+ : Addition\n- : Subtraction\n* : Multiplication\n/ : Division\n^ or ** : Exponentiation\n%% : Modulus (remainder from division)\n%/% : Integer division\n\nUse these to solve the questions below:\nFill in the blank so that the result of the sum is 10. You need to delete the ______ and replace it with a number.\n\n\n\n\n\n\n\n\n\n\n\n\nFill in the blank so that the result of the sum is 12.\n\n\n\n\n\n\n\n\n\n\n\n\nFill in the blank so that the result of the sum is 81."
  },
  {
    "objectID": "exercises/01_intro_to_r.html#programming-concepts",
    "href": "exercises/01_intro_to_r.html#programming-concepts",
    "title": "Introduction to R",
    "section": "Programming concepts",
    "text": "Programming concepts\nWhile it is not required to be an experienced computer programmer to use R, there is still a set of basic programming concepts that new R users need to understand. We will cover these first. You do not need to memorise these things.\n\nObjects\nIn R, data can be stored in objects. An object can be thought of as a container that holds data. You can create an object by assigning a value to a name using the assignment operator &lt;-. In the example below, I assign the value 5 to the object x, and the value 10 to the object y. We can then perform maths or other operations using these objects. Calculate the sum of x and y using + on the line below.\n\n\n\n\n\n\n\n\n\nx &lt;- 5\ny &lt;- 10\nx + y\n\n\n\n\nAdd a third object called z and assign it the value 12. Write a math equation that will output the value 24, using x, y, and z only.\n\n\n\n\n\n\n\n\n\nx &lt;- 5\ny &lt;- 10\nz &lt;- 12\n\ny / x * z\n\n\n\n\nObjects can hold any sort of data in R. It could be a single value like in the above example, multiple values, text, a whole dataset, or a plot.\n\n\nData types\nIn R, data can come in various types, and it’s important to understand these types to manipulate and analyse data effectively. Here are some of the most common data types in R:\n\nNumeric: Represents numbers and can be either integers or floating-point numbers. For example, 42 and 3.14 are numeric values.\nCharacter: Represents text or string data. Character values are enclosed in quotes, such as \"Hello, world!\".\nLogical: Represents boolean values, which can be either TRUE or FALSE.\nFactor: Used to represent categorical data. Factors are useful for storing data that has a fixed number of unique values, such as “Species A” and “Species B” for species ID.\n\nNote that these are similar, but conceptually different, to the variables types we covered in the lecture. However, the variable types we covered are often encoded in R using these data types:\n\nCategorical variables:\n\nNominal: we will generally use either a character or a factor data type. If used in a statistical test or to make a plot, character data is usually automatically converted to a factor. If your nominal variable is represented by a number (e.g., Forest 1,2,3…), then it is usually best to explicitly convert it to either a character or a factor.\nOrdinal: must be a factor, as you can set the order of the levels witin the factor to the intended order. By default, the order will be determined by alpha-numeric order (A,B,C, 1,2,3).\n\nQuantitative variables\n\nDiscrete: numeric, and specifically, an integer. R will infer the type of numeric data (integer or double (with decimal)) from the data.\nContinuous: numeric, and specifically, a double.\n\n\n\n\nVectors\nVectors are one of the most basic data structures in R. A vector is a sequence of data elements of the same basic type. We will sometimes directly use vectors in this course, so it will be good to be familiar with them.\n\nCreating Vectors: You can create a vector using the c() function, which stands for “combine” or “concatenate”. For example, here I create 3 vectors, and assign them to different objects:\n\n\n\n\n\n\n\n\n\nAccessing Elements: You can access elements (position) of a vector using square brackets []. For example, to access the second element of character_vector:\n\n\n\n\n\n\n\n\nNote that in R, the first position is [1], not [0] like in some programming languages.\nVector Operations: You can perform operations on vectors. These operations are applied element-wise. For example:\n\n\n\n\n\n\n\n\nNote that every value in the vector gets multiplied and returned.\nVector Length: You can find the length (number of values in it) of a vector using the length() function:\n\n\n\n\n\n\n\n\n\n\nDataframes\nDataframes are like spreadsheets. They have rows and columns, and all columns are the same length. These are the primary way we will represent data in this course.\n\n\n\nspecies\nmass_g\nsex\n\n\n\n\nblue_tit\n9.1\nmale\n\n\nblue_tit\n10.6\nmale\n\n\nsparrow\n27.3\nfemale\n\n\n\nWe will come back to them soon.\n\n\nBoolean and logical operators\nBoolean operators are used to perform logical operations and return boolean values (TRUE or FALSE). We will use them in this course to describe our hypotheses. Here are the most common boolean operators in R:\n\nComparison Operators: These operators compare two values and return a boolean value.\n\n== : Equal to\n!= : Not equal to\n&lt; : Less than\n&gt; : Greater than\n&lt;= : Less than or equal to\n&gt;= : Greater than or equal to\n\n\nFor example, this bit of code should evaluate to TRUE:\n\n\n\n\n\n\n\n\nAnd this should be FALSE:\n\n\n\n\n\n\n\n\nUse the operators above to fill in the blanks below such that the code will evaluate to TRUE:\n\n\n\n\n\n\n\n\n\n100 == 100\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- 48\n\n8 + p == 56\n\n\n\n\n\n\n\n\n\n\n\n\n\nq &lt;- 24\nr &lt;- 88\n\n1q + 65 &gt; r\n\n1\n\nAny number &gt; 64 will work.\n\n\n\n\n\n\nWe can now add in some logical operators:\n\nLogical Operators: These operators are used to combine multiple boolean expressions.\n\n& : Logical AND\n| : Logical OR\n! : Logical NOT\n\n\nFor example, this bit of code should evaluate to TRUE, because both the first part 1 + 3 == 4 and the second part 5 &gt;= 4 is TRUE:\n\n\n\n\n\n\n\n\nWhereas this evaluates to FALSE, because only the first part is TRUE:\n\n\n\n\n\n\n\n\nBut if we change the & to an OR operator |, it evaluates to TRUE because at least one part of it is TRUE:\n\n\n\n\n\n\n\n\nUse the operators above to fill in the blanks below such that the code will evaluate to TRUE:\n\n\n\n\n\n\n\n\n\nfruit_a &lt;- \"apple\"\nfruit_b &lt;- \"banana\"\n\n1(fruit_a != fruit_b) & (1.5 &gt; 1.2)\n\n1\n\nOR | would also work here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfruit_a &lt;- \"apple\"\nfruit_b &lt;- \"banana\"\n\n(fruit_a == fruit_a) | (35 + 12 &gt; 47)\n\n\n\n\n\n\nFunctions\nFunctions perform tasks in R. Functions can take inputs, called arguments, and return outputs. We put the arguments inside the brackets. For example, in R there is a function called mean(). This function’s first argument x should be a vector of numeric data. The function then outputs the mean as a single numeric value. For example, here we assign a vector of tree heights (cm) to an object called trees. We then calculate the mean tree height using the mean() function.\n\n\n\n\n\n\n\n\nNote that if we are going to supply arguments in the order that the function expects them, we do not have to tell the function which object is for each argument. Since mean() expects the first argument to be the vector you want the mean of, we can also write:\n\n\n\n\n\n\n\n\nTo find out what a function can do, and its arguments, use can write ?function_name, and the R helpfile will be returned for that function (e.g., ?mean). These helpfiles can be confusing at first, but the more you use R, the more they will make sense.\nWe will work with functions a lot in this course, so don’t worry if it still seems confusing.\n\n\nPipes\nOne of the final concepts I will introduce is the pipe operator |&gt;. Note that you will often see it written as %&gt;% when searching online. This is for historical reasons (R by default did not have a pipe operator until recently, so people had made their own). |&gt; comes with R by default now, while %&gt;% requires you to load a package called magrittr first (we will cover packages soon).\nPipes allow you to write code in a way that often makes more sense to people, especially non-programmers. To explain, here’s an example. Note that this is not real code, so you cannot run it.\nSay I wanted to run 3 different functions on a dataframe called my_data. The functions are function_1(), function_2(), and function_3(). Imagine function_1() first transforms my data into the right scale, function_2() then performs a statistical test, and function_3() then makes a plot (again, these are not real functions, just for the example).\nI could write that in a few ways. The first way would look like this:\n\n1my_data_1 &lt;- function_1(my_data)\n2my_data_2 &lt;- function_2(my_data_1)\n3my_data_final &lt;- function_3(my_data_2)\n\n\n1\n\nThe original data, my_data, is passed to function_1(), and the result is stored in my_data_1.\n\n2\n\nThe transformed data, my_data_1, is then passed to function_2(), and the result is stored in my_data_2.\n\n3\n\nFinally, the data from my_data_2 is passed to function_3(), and the result is stored in my_data_final.\n\n\n\n\nWhile this method is quite clear to read, it creates a lot of objects that we might not want to do anything with. This is not a huge issue, but could become one if you are working with very large data sets.\nWe could also write it like this:\n\nmy_data_final &lt;- function_3(function_2(function_1(my_data)))\n\nWe can wrap functions within functions to put this whole operation on one line. This gets rid of those extra objects, having only a my_data_final as the output. However, the order in which the functions are written no longer matches the order in which they are run. In the above example, function_1() runs first, then function_2(), then function_3(). But they are written in reverse order when we read it left to right.\nA final method of writing this makes use of pipes |&gt;, and has the best of both approaches:\n\nmy_data_final &lt;- my_data |&gt; function_1() |&gt; function_2() |&gt; function_3()\n\nPipes also allow us to spread our code over multiple lines, and the |&gt; will look for the next bit of code on the next line if nothing comes after it:\n\nmy_data_final &lt;- \n  my_data |&gt; \n  function_1() |&gt; \n  function_2() |&gt; \n  function_3()\n\nAll the above examples have the same my_data_final output, but are just written in different ways. The computer reads them all identically, so the main benefit is how readable your code is.\nIn this course, we will use pipes extensively, along with a set of packages that are designed for this kind of workflow. Below, rewrite the examples to use pipes. You can check the solutions tab to see if you are on the right track:\n\n\n\n\n\n\n\n\n\n1trees |&gt; mean()\n\n1\n\nTake the trees vector, and then pipe|&gt; it into the mean() function.\n\n\n\nThe log() function performs a natural logarithm transformation of the data.\n\n\n\n\n\n\n\n\n\n1trees |&gt;\n  log() |&gt;\n  mean() \n\n1\n\nTake the trees vector, and then pipe|&gt; it into the log() function, then into the mean() function.\n\n\n\n\n\nPackages\nAn R package is a set of functions, data and/or information that someone else has written, that you can first load, then use in your own R code. Packages are written by other R users, and distributed for free via repositories, like The Comprehensive R Archive Network (CRAN).\nR packages are often used to save you time. While all the functions in an R package are written with R, and you could write them again yourself, why bother? If someone else has done it already and shared it, fantastic! In this course, we are going to use two package “families”. They are tidyverse and tidymodels. Note that both start with tidy. Remember from the lecture, that tidy refers to a particular format of data, and these packages all assume your data will be in the format, and will always return data in that format. They are also all built with pipes in mind, and are designed to make complex programming tasks (especially those performed by data scientists, of which biology fits in well) very easy. We will cover these packages in detail soon, but know to use them you need to do two things:\n\nInstall the package. This needs to be done once on your computer, using the install.packages() command. For examples:\n\n\ninstall.packages(\"ggplot2\")\n\nThis will install ggplot2, a package for plotting data. It will install it from CRAN by default, and probably (assuming you are in Sweden) will be downloaded from a server in Umeå.\n\nWe now need to load the package, so that we can access it while we write code. To do that, we use the library() function.\n\n\n1library(ggplot2)\n\n\n1\n\nNote that we no longer require the \" around the package name. But the function would still work if you did include them.\n\n\n\n\nBelow I have written some code that makes a plot using an inbuilt R dataset called iris using the package ggplot2. But if you try to run it, you will get an error. The ggplot2 package has already been installed, so fix the code by loading the ggplot2 package before the code that makes the plot.\n\n\n\n\n\n\n\n\n\n\n\n\n1library(ggplot2)\niris |&gt;\n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) +\n  geom_point()\n\n1\n\nMake sure to load the ggplot2 package before the ggplot() function. Code is always executed top to bottom.\n\n\n\nThat was a lot of concepts in a very short amount of time! Take a well deserved break before the next exercise."
  },
  {
    "objectID": "exam.html",
    "href": "exam.html",
    "title": "Exam guide",
    "section": "",
    "text": "The exam will be split into two halves:",
    "crumbs": [
      "Exam guide"
    ]
  },
  {
    "objectID": "exam.html#part-1-knowledge-reasoning-and-understanding-50",
    "href": "exam.html#part-1-knowledge-reasoning-and-understanding-50",
    "title": "Exam guide",
    "section": "Part 1: Knowledge, reasoning and understanding (50%)",
    "text": "Part 1: Knowledge, reasoning and understanding (50%)\n\nClosed book (no notes, no internet, etc)\nAnswer either by hand or in a text document\nQuestions provided in English\nAnswer in either English or Swedish\n\nThis section will be a mixture of short answer and multiple choice questions that cover the topics we have talked about during this course. You will not have access to any materials during this section (i.e., closed book). You can spend as long as you like on this section, but I expect it will not take more than 1 hour. Once you have completed part 1, you will need to submit your answers before starting part 2.",
    "crumbs": [
      "Exam guide"
    ]
  },
  {
    "objectID": "exam.html#part-2-handling-of-biological-data-and-applied-statistics-in-r-50",
    "href": "exam.html#part-2-handling-of-biological-data-and-applied-statistics-in-r-50",
    "title": "Exam guide",
    "section": "Part 2: Handling of biological data and applied statistics in R (50%)",
    "text": "Part 2: Handling of biological data and applied statistics in R (50%)\n\nOpen book (but you must not plagiarize text, including from AI sources)\n\nOpen book is primarily for coding related issues\n\nWrite your code and answers in an RMarkdown document (which you will submit at the end)\nQuestions provided in English\nAnswer in either English or Swedish\n\nThis section will be a full analysis of a dataset, from importing, cleaning (if needed), plotting, calculating confidence intervals and performing hypothesis tests to answer a specific question, as we have done in the exercises.\n\nThis is not a programming course\nSince this is not a programming course, you will not be penalized for coding mistakes. It is therefore very important that you write clearly what your intentions were, and what your conclusions are.\nIf your code will not work and you have no idea why, you may raise your hand to ask me to review it. If it is a coding related issue, I will show you how to fix it (if I can). If it is a knowledge or learning outcome related issue (e.g., what test statistic to use), I cannot answer.\nIf you know what you want to do, but do not know how to write the code in R and cannot figure it out from your notes or other materials, write a written description of what you would do. You can still recieve points for this, if you can show your understanding.",
    "crumbs": [
      "Exam guide"
    ]
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Topic\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nExercise\n\n\nDate\n\n\nTopic\n\n\n\n\n\n\nExercise 1\n\n\n2025-03-25\n\n\nIntroduction to R\n\n\n\n\nExercise 2\n\n\n2025-03-25\n\n\nDescriptive statistics in R\n\n\n\n\nExercise 3\n\n\n2025-03-26\n\n\nHow to install R on your local computer\n\n\n\n\nExercise 4\n\n\n2025-03-26\n\n\nHandling data using RStudio\n\n\n\n\nExercise 5\n\n\n2025-03-28\n\n\nEstimation, uncertainty and error\n\n\n\n\nExercise 6\n\n\n2025-03-28\n\n\nTest your skills\n\n\n\n\nExercise 7\n\n\n2025-04-02\n\n\nAnalysis of variance (ANOVA)\n\n\n\n\nExercise 8\n\n\n2025-04-03\n\n\nTests of, and associations between, categorical variables\n\n\n\n\nExercise 9\n\n\n2025-04-04\n\n\nCorrelation and linear regression I\n\n\n\n\nExercise 10\n\n\n2025-04-04\n\n\nTest your skills II\n\n\n\n\nExercise 11\n\n\n2025-04-07\n\n\nArticle exercise\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html",
    "href": "exercises/02_descriptive_statistics.html",
    "title": "Descriptive statistics in R",
    "section": "",
    "text": "In this exercise, we will use descriptive statistics to describe datasets. We will also make some figures of the data. You can do everything using the R code blocks on the page. If you want to, you can also try run the code on your computer, but we will do that properly in the next exercise.\nThe palmerpenguins dataset contains data about some penguins. From the data website:\nThe data has already been loaded into the R environment, but if you wanted to follow along on your own computer, you can load it by first installing the palmerpenguins package, and then loading the dataset.\nShow how to install the palmerpenguins package\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\nWe are also going to use the tidyverse set of R packages for this exercise. They have also already been loaded, but as usual if you wanted to run this on your own computer, you would have to install and load the tidyverse package too.\nShow how to install the tidyverse package\ninstall.packages(\"tidyverse\")\nlibrary(palmerpenguins)\nOk, let’s get started."
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#the-grammer-of-graphics",
    "href": "exercises/02_descriptive_statistics.html#the-grammer-of-graphics",
    "title": "Descriptive statistics in R",
    "section": "The grammer of graphics",
    "text": "The grammer of graphics\nThe grammer of graphics gives us a way to describe any plot. ggplot2 then allows us to make that plot, using a layered approach to the grammer of graphics.\nUsing this approach, we can say a statistical graphic is a mapping of data variables to aesthetic attributes of geometric objects (Chester et al. 2025).\nWow. What does that mean? Let’s break it down.\nA ggplot2 plot has three essential components:\n\ndata: the dataset that contains the variables you want to plot\ngeom: the geometric object you want to use to display your data (e.g. a point, a line, a bar).\naes: aesthetic attributes that you want to map to your geometric object. For example, the x and y location of a point geometry could be mapped to two variables in your dataset, and the colour of those points could be mapped to a third.\n\nAs I said before, ggplot2 uses a layered approach to the grammer of graphics. This makes it very easy to start contructing plots by putting together a “recipe” step-by-step. Let’s walk through an example.\n\nWe want to make a scatterplot that shows the relationship between body_mass_g and bill_length_mm. Imagine we are interested to see if bigger penguins also have bigger bills? (We will do correlation analysis later on in the course, this is just a nice example for learning ggplot2).\nLet’s map out what we need to describe that plot:\n\ndata is the penguins dataset, as that is where the body_mass_g and bill_length_mm variables are.\ngeom we are going to represent the data using a point, as we are making a scatter plot.\naes is how we describe where each point should be. For this example, we could map the x (horizontal position) of the point to body_mass_g and the y position (vertical position) to bill_length_mm.\n\nSo now we have the recipe, let’s start building layer by layer. First we will add the data by providing it to the ggplot() function as an argument. Try running this!\n\n\n\n\n\n\n\n\nWow, beautiful! But perhaps some things are missing. Let’s map our data. We use the aes() to tell R that everything inside it is going to be used as an aesthetic mapping, and that the names of the variables we mention come from the dataframe. We then provide that to ggplot()’s mapping argument, as shown:\n\n\n\n\n\n\n\n\nAgain, still not quite there. We need to actually show the data! We need to add some geometry. To do that we, use the + operator. While this is usually reserved for maths, ggplot2 hijacks it to add layers to a plot. We can add a point geometry like this (you might need to use the hoziontal scroll wheel to see the end of the first line):\n\n\n\n\n\n\n\n\nLooking good! Notice you got a warning. The warning is important to pay attention to, as it is telling you that two rows (penguins) have not been plotted, as they contain missing values. These are the NA values we talked about earlier. Two penguins must have had an NA for at least one of our plotting variables, body_mass_g or bill_length_mm (as we need both to place the point).\nLet’s add one more aesthetic to our data. Our dataset contained data for three different penguin species. Let’s map species to the colour of our points.\nYou need to modify the code above by adding a 3rd argument within the aes() function. In R, we seperate arguments within functions with a , as you can see between x = body_mass_g and y = bill_length_mm. Add another , then write colour = species. Then re-run the code.\n\n\n\n\n\n\n\n\n\n1ggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm, colour = species)) +\n  geom_point()\n\n1\n\nAdd colour as a third aesthetic, mapped to species\n\n\n\nYou notice we now have a legend that tells us which colour is which species. ggplot2 has also chosen a default colour scheme for us.\nAnswer the following questions:\n\nIf someone told you that heavier penguins tend to have longer bills, and showed you this graph as proof, would you believe them? Why? Do you think this applies to all penguin species in the dataset?\nModify the code above to instead show bill_depth_mm on the x axis. Which penguin species do you think match each bill description?\n\nShort and wide bills\nLong and wide bills\nLong and narrow bills\n\n\n\nLet’s get back to understanding each of the variables. For continuous variables, a histogram is a good place to start, as it shows us the range and the shape of the distribution. To make a histogram with ggplot, we use geom_histogram() as our geometry. geom_histogram() is a bit of a special geom_, as it does all the calculations needed to make a histogram for us, such as binning our data and counting the number of bits of data in each bin. We also need to only provide an x aesthetic value, and the y value is calculated for us by geom_histogram().\n\n\n\n\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram()\n\n1ggplot(data = penguins, mapping = aes(x = bill_length_mm)) +\n  geom_histogram()\n\nggplot(data = penguins, mapping = aes(x = bill_depth_mm)) +\n  geom_histogram()\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm)) +\n  geom_histogram()\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram()\n\n1\n\nReplace the variable assinged to x with the variable you want to plot.\n\n\n\nNotice we get the warning again, that data (NA values) have been removed.\nCopy and modify the above code to show the other continuous variables.\n\nDo they all look like bell-shaped (normal) distributions? Are any very different from a normal distribution (e.g., has more than one distinct peaks)? Can you think why this might be?\n\n\nNow let’s look at our other variables. species and island and sex seem to be categorical nominal variables, each with three different categories. What about year? It’s integer data (1,2,3, etc) so that might suggest we should treat it like a quantitative discrete variable. But, it only has three levels across the entire dataset. This suggests to me that it instead is a categorical ordinal variable. It is the year the penguin was caught and measured. I think you could also make an arguement that this is not an ordinal variable, and instead is nominal. It would depend if you think penguins in 2007 are going to be more similar to penguins in 2008, than penguins in 2009 (maybe because of gradual changes in climate), or if you think any differences between years would be random (maybe some years are better or worse than others, but this is not predictable). Either way, we can also visualise it using the same method.\nLet’s look at how much of our data comes from each category in each variable. To do that, we could use a bar chart. Like geom_histogram(), geom_bar() does some calculation for us. Specifically, it counts how many rows of data are assigned to each category, and then uses that for our y aesthetic.\n\n\n\n\n\n\n\n\n\n# Part 1\nggplot(data = penguins, mapping = aes(x = species)) + \n  geom_bar()\n\n1ggplot(data = penguins, mapping = aes(x = island)) +\n  geom_bar()\n\nggplot(data = penguins, mapping = aes(x = year)) +\n  geom_bar()\n\nggplot(data = penguins, mapping = aes(x = sex)) +\n  geom_bar()\n\n# Part 2\n2ggplot(data = penguins, mapping = aes(x = island, fill = species)) +\n  geom_bar()\n\n1\n\nReplace the variable assinged to x with the variable you want to plot.\n\n2\n\nAdd fill as an aesthetic, and map it to species.\n\n\n\n\nAs you did before, copy and modify the code to make a bar chart for island, sex, and year.\nUsing what you learned to make the first scatter plot, can you add another aesthetic to make a plot that shows what proportion of the penguins on each island are which species? Are all species present on all islands?\n\nHint: Instead of using colour, you might want to try fill. To understand why, try each one!\n\nFinally for plotting today, we will make some box plots. Box plots allow us to visualize the distribution of a continuous variable and to compare distributions across different levels of a categorical variable. A box plot displays the median, quartiles, and potential outliers of the data.\n\nTo create a box plot in ggplot2, we use geom_boxplot(). Again, this is a very helpful geom_, as it does all of the required calculations (median, quartiles, etc) for us.\nUsing what you have learned, try to create this boxplot yourself first (you can copy code from above and modify it). Create a box plot to compare body_mass_g across different species. Think what variables should be assigned to which aesthetics.\n\n\n\n\n\n\n\n\n\n1ggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n2  geom_boxplot()\n\n1\n\nAssign the variables to the aesthetics.\n\n2\n\nUse the boxplot geom function."
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#calculating-individual-descriptive-statistics",
    "href": "exercises/02_descriptive_statistics.html#calculating-individual-descriptive-statistics",
    "title": "Descriptive statistics in R",
    "section": "Calculating individual descriptive statistics",
    "text": "Calculating individual descriptive statistics\nFor all the descriptive statistics we covered in the lecture, you could calculate them using the maths functions alone from the last exercise. However, they have also been implemented in their own functions, which saves us some time:\n\nmean(): Computes the arithmetic mean of a numeric vector.\nmedian(): Computes the median of a numeric vector.\nmin(): Returns the minimum value in a numeric vector.\nmax(): Returns the maximum value in a numeric vector.\nquantile(): Computes the quantiles of a numeric vector.\n\n1st quartile: quantile(x, prob = 0.25), where x is a numeric vector.\n3rd quartile: quantile(x, prob = 0.75), where x is a numeric vector.\n\nvar(): Computes the variance of a numeric vector.\nsd(): Computes the standard deviation of a numeric vector.\nlength(): Count the number of bits of data in a vector.\n\nNote that most of these function, by default, will produce an error if you have a single NA in the vector. If you use a vector with NA values, you need to explicitly tell the function to remove the NA values, by adding the argument rm.na = TRUE.\nYou’ll notice that each of these take a vector as input (check the last exercise for a review). Each column/variable in our dataframe penguins is actually just a vector. So we can use these functions on individual columns. To do that, we need to extract the column/variable we are interested in, then use the statistic function on it. For example, to calculate the mean of the variable flipper_length_mm, we could write it like this:\n\n\n\n\n\n\n\n\nTo break down what’s going on here. 1. On the first line, we write the name of the dataframe that contains the variable we want to use. 2. This is then piped |&gt; into the next line, where we use pull() to “pull out” the variable we want. 3. We then again use a pipe |&gt; to send that to the mean() function. Since bill_length_mm contains some NA values, we need to put na.rm = TRUE (NA remove) inside mean().\nUse what we have learned above to complete the following exercises by filling in the blanks:\nCalculate the median of body_mass_g:\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n  pull(body_mass_g) |&gt; \n  median(na.rm = TRUE)\n\n\n\n\n\nCalculate the standard deviation of bill_length_mm:\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n  pull(bill_length_mm) |&gt; \n  sd(na.rm = TRUE)\n\n\n\n\n\nCalculate the 1st quartile of bill_depth_mm:\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n  pull(bill_length_mm) |&gt; \n  quantile(prob = 0.25, na.rm = TRUE)\n\n\n\n\n\nCalculate the IQR of body_mass_g:\n\n\n\n\n\n\n\n\n\nfirst_quartile &lt;- \n  penguins |&gt;\n  pull(body_mass_g) |&gt; \n  quantile(prob = 0.25, na.rm = TRUE)\n\nthird_quartile &lt;- \n  penguins |&gt;\n  pull(body_mass_g) |&gt; \n  quantile(prob = 0.75, na.rm = TRUE)\n\nthird_quartile - first_quartile"
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#making-tables-of-descriptive-statistics",
    "href": "exercises/02_descriptive_statistics.html#making-tables-of-descriptive-statistics",
    "title": "Descriptive statistics in R",
    "section": "Making tables of descriptive statistics",
    "text": "Making tables of descriptive statistics\nOften we want to provide a table of descriptive statistics about our variables. To make our own (beyond what summary() can offer), we need to do a bit of data manipulation. To do that, I need to introduce a few functions from the package dplyr (part of tidyverse), which provides a grammer of data manipulation for us to use. Again, like ggplot2, this grammer is often much easier for non-programmers to understand, and makes doing common tasks easier for everyone.\nIn this next section, we will use the following functions:\n\ngroup_by: all functions that come after this will provide an output for each category in the grouping variable.\nsummarise(): produces a summary table by computing summary statistics on a variable.\n\nLet’s start by constructing a table that will describe the bill_length_mm variable, but we want to compute the statistics for each penguin species. On the first line we write the dataframe name, penguins, which we then pipe |&gt; into the next line. On the second line, we tell R to remove all penguins that have an NA for their bill length. This saves us from needing to write na.rm = TRUE many times. This gets piped |&gt; into the next line, where we specify our grouping variable, which in this case, is species. When then use another pipe |&gt; to send that onto the next line, where we will use summarise() to make a summary table. Inside summarise() we define what summary statistics we want to calculate, and what we want to call them in the output. For example, here we calculate the mean() of bill_length_mm, and tell the function to call it mean_bill_length_mm in the output.\n\n\n\n\n\n\n\n\nThe output contains our new mean_bill_length_mm column, but for each penguin species. We can add other new columns with other descriptive statistics in a similar fashion. Note that instead of making the 4th line very long, we can put new arguments on seperate lines, as long as those lines end with a comma:\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n3  drop_na(bill_length_mm, sex) |&gt;\n2  group_by(species, sex) |&gt;\n  summarise(\n    mean_bill_length_mm = mean(bill_length_mm),\n1    median_bill_length_mm = median(bill_length_mm),\n    sd_bill_length_mm = sd(bill_length_mm)\n    )\n\n1\n\nNote the comma at the end!\n\n2\n\nNote the comma between the variables!\n\n3\n\nThis remove all rows where sex was NA, removing the unwanted group.\n\n\n\nAdd another column to the output table above that calculates the standard deviation of bill_length_mm.\nWe can add more than one grouping variable, by simply listing it within group_by(). For example, try grouping your output by both species and sex. Note that this produces an potentially unwanted group, how could you get rid of it?"
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#the-question",
    "href": "exercises/02_descriptive_statistics.html#the-question",
    "title": "Descriptive statistics in R",
    "section": "The question",
    "text": "The question\n\nSexual dimorphism is the condition where sexes of the same species exhibit different morphological characteristics, including characteristics not directly involved in reproduction. Differences may include size, weight, color, markings, or behavioral traits.\n\nFrom this definition of sexual dimorphism above, we will try and address the following question:\nIs [chosen penguin species] sexually dimorphic?\nYou should choose one penguin species to work with (Adelie, Chinstrap or Gentoo)."
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#the-hypothesis",
    "href": "exercises/02_descriptive_statistics.html#the-hypothesis",
    "title": "Descriptive statistics in R",
    "section": "The hypothesis",
    "text": "The hypothesis\nBefore beginning any scientific study, we need a hypothesis, for two reasons. The first is practical: if you do not have a hypothesis in mind, you’ll likely not collect data in an effective manner and you will waste your time. The second is more fundamental: all statistical tests are based on testing a hypothesis. So, to meaningfully conduct a statistically test, you need a hypothesis.\nThe hypothesis is an explanation for your data. Two types exist:\n\nA null hypothesis, where we assume that the factor we are studying (in this case sex) has no effect on our data.\nAn alternative hypothesis is the opposite of the null hypothesis. It states that the factor we are studying (sex) does affect our data.\n\nUsing the above examples, can you phrase both the null and alternative hypotheses?\n\n\n\n\n\n\nSuggested hypotheses\n\n\n\n\n\n\nNull hypothesis: Penguins do not differ in size between sexes.\nAlternative hypothesis: Penguins are different in size between sexes."
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#the-experiment",
    "href": "exercises/02_descriptive_statistics.html#the-experiment",
    "title": "Descriptive statistics in R",
    "section": "The experiment",
    "text": "The experiment\nUsually this is the stage where you would design an experiment to test your hypothesis. You need to think what is the population you want to make inferences about, and what would be an appropriate sample to do so.\nFor this exercise, assume that the penguins data is a representative sample (collected randomly) of your chosen species. What is the population we can then make inferences about?\n\n\n\n\n\n\nSuggested population\n\n\n\n\n\nThe species you have chosen. If you are worried that the sample is not truly representative (it only comes from three islands after all), you might be cautious and restrict your inferences to only penguins of your species from these islands."
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#collect-and-describe-the-data",
    "href": "exercises/02_descriptive_statistics.html#collect-and-describe-the-data",
    "title": "Descriptive statistics in R",
    "section": "Collect and describe the data",
    "text": "Collect and describe the data\nBefore we go any further, we should create a subset of our data that is just your chosen penguin species, as that is the population we want to make inferences about here. We can use filter() to make a “filter” for our data. Only rows that satisfy our conditional statement will be allowed through the filter. Replace ______ with the name of your chosen species. We are also only interested in rows where we have information about the penguin’s sex. We will also remove the rows with NA for sex using some logic from exercise 1. Run the code below, and going forward, we should use the my_species dataframe.\n\n\n\n\n\n\n\n\nYou also should decide what variable(s) you will use to assess sexual dimorphism. Now, by copying and modifying code from previous sections, calculate the mean and standard deviation of that variable for each sex.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuggested code if you are stuck\n\n\n\n\n\n\ndescriptive_data &lt;-\n  my_species |&gt; \n  group_by(sex) |&gt;\n  summarise(\n1    mean_body_mass_g = mean(______, na.rm = TRUE),\n    sd_body_mass_g = sd(______, na.rm = TRUE),\n    )\n\n2mean_data\n\n\n1\n\nReplace _____ with your chosen variable\n\n2\n\nTo print the results\n\n\n\n\n\n\n\nMake a plot that shows you chosen variable for each sex. Again, copy and modify code from above.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuggested code if you are stuck\n\n\n\n\n\n\nmy_species |&gt;\n1  ggplot(aes(x = sex, y = ______)) +\n  geom_boxplot()\n\n\n1\n\nReplace _____ with your chosen variable"
  },
  {
    "objectID": "exercises/02_descriptive_statistics.html#analysing-the-data",
    "href": "exercises/02_descriptive_statistics.html#analysing-the-data",
    "title": "Descriptive statistics in R",
    "section": "Analysing the data",
    "text": "Analysing the data\nWe now want to test if these means (from a sample) likely differ between sexes in our population.\nOne way we can do that is to start by imagining the world in which our null hypothesis is true. In that world, there is no difference between the sexes in your chosen variable. In that world, a penguin being labelled as male or female should have no effect on your chosen variable. In otherwords, if our null hypothesis is true, then randomly assiging sex to each penguin should not alter the difference in means between the sexes.\nThis idea is the foundation of a type of statistical inference called permutation or randomisation testing.\nLet’s try implement it here. To do that, we will use the R package infer (which I have already loaded).\n\n\n\nThe infer design\n\n\n\nCalculating the difference\nFirst, we need to specify() which variables are relevant to our hypothesis. This extracts the data we need to test our hypothesis. We then calculate() the \"diff in means\", specifying that we want to get the difference as male-female. A positive value therefore indicated male biased sexual dimorphism. Fill in the variable you have chosen and run the code:\n\n\n\n\n\n\n\n\n\n\nGenerating data assuming our null hypothesis\nNext, we need to state our null hypothesis. In this case, our null hypothesis is that the explanatory variable sex has no effect on the response variable. Therefore, we hypothesize() (if the null is true) \"independence\" between the explanatory and response variables.\n\nmy_species |&gt;\n  specify(response = ______, explanatory = sex) |&gt;\n  hypothesize(null = \"independence\")\n\nNow, we need to randomly shuffle the sex variable, which if our null hypothesis is true, should have little affect on the difference in means. We also need to do this a lot of times (1000+). First we generate() 1000 datasets where the sex variable has been randomly shuffled (\"permute\"). Then in each of those datasets, we calculate() the difference in means between the sexes, as we did for our deal difference in means above. Fill in the variable you have chosen and run the code:\n\n\n\n\n\n\n\n\nNow, let’s visualise our null distribution null_diff_means.\n\n\n\n\n\n\n\n\nThis shows the distribution of values of sexual dimorphism we could observe if the null hypothesis was true.\n\n\nHow extreme was our real data?\nWe can use the position of the real calculated difference between the sexes in the null distribution to infer how likely our null hypothesis was true. If the null hypothesis is true, then our real difference will probably lie somewhere near the middle of our null distribution, as after all, sex had no effect on the chosen variable.\nHowever, if sex did have an effect on the chosen variable (that is, our alternative hypothesis was correct), then we would expect the original sex assignments to be a very special arrangement. As such, our real difference should lie close to the tails of the null distribution (or maybe far beyond it).\nLet’s plot it now to see. We can use the function shade_p_value() to do this (we will come back to what a p-value is later). We specify the direction = \"two-sided\" because our hypothesis did not make an assumption as to if the sexual dimorphism will be male or female biased.\n\n\n\n\n\n\n\n\nWhere did your real difference in means end up? Use the above text to decide if you think your null hypothesis, or your alternative hypothesis, is most likely true.\nFinally, phrase your findings in biological terms. What do your findings suggest?\nWhen you are done, show the teacher your findings."
  },
  {
    "objectID": "exercises/04_handling_data.html",
    "href": "exercises/04_handling_data.html",
    "title": "Handling data using RStudio",
    "section": "",
    "text": "Launch RStudio. It should detect your R installation automatically, but if not, a window will open asking you to select it. If R does not appear here, I suggest you restart your computer first.\nYou should be met by a scene that looks like this:\n\n\n\nA screenshot of a new RStudio installation on macOS.\n\n\nRstudio is designed around a four panel layout. Currently you can see three of them. To reveal the fourth, go to File -&gt; New file -&gt; R markdown... This will open an RMarkdown document, which is a form of coding “notebook”, where you can mix text, images and code in the same document. We will use these sorts of documents extensively in this course. Give your document a title like “BIOB11 Exercise 4”. You can put your name for author, and leave the rest as default for now. Click OK. Now your window should look something like this:\n\n\n\nA screenshot of RStudio on macOS with an RMarkdown file open, and the panels labelled.\n\n\n\nSource: This is where we edit code related documents. Anything you want to be able to save should be written here.\nConsole: the console is where R lives. This is where any command you write in the source pane and run will be sent to be executed.\nEnvironments: this panel shows you objects loaded into R. For example, if you were to assign a value to an object (e.g.x &lt;- 1), then it would appear here.\nOutput: this panel has many functions, but is commonly used to navigate files, show plots, show a rendered RMarkdown file or to read the R help documentation.\n\n\n\nRMarkdown is a file format for making dynamic documents with R. It combines plain text with embedded R code chunks that are run when the document is rendered, allowing you to include results and your R code directly in the document. This makes it a powerful tool for creating reproducible analyses, which are extremely important in science.\nThe RMarkdown document you opened has some example text and code. An RMarkdown document consists of three main parts:\n\nYAML Header: This section, enclosed by --- at the beginning and end, contains metadata about the document, such as the title, author, date, and output format.\nText: You can write plain text using Markdown syntax to format it. Markdown is a lightweight markup language with plain text formatting syntax, which is easy to read and write.\nCode Chunks: These are sections of R code enclosed by triple backticks and {r}. You can click the green arrow to run all the code in a code chunk, or run each line of code using the Run button, or by using Ctrl+Enter (Windows) or Cmd+Enter (macOS)When the document is rendered, the code is executed, and the results are included in the output.\n\nNotice at the top left of the Source panel, there are two buttons: Source and Visual. These allow you to switch betwee two views of the RMarkdown document. The Source view is what you are looking at, and it is the raw text document. You can also use the Visual view, which allows you to work in a WYSIWYG (what you see is what you get) view, similar to Microsoft Office or other text editors. This “renders” your markdown code for you while you write. It also gives you a series of menus to help you format text, which means you do not need to learn how to write markdown code (although it is extremely simple, and you likely know some already).\nWhich ever view you prefer (and you can switch as often as you like), the code part stays the same. It is primarily there for editing the text around your code.\n\n\n\nBefore we go any further, we need to change some default settings in RStudio.\nGo to Tools -&gt; Global Settings, then:\n\nGo to the General tab.\n\nUn-tick “Restore .RData into workspace at startup”\nSet “Save workspace to RData on exit:” to Never.\n\nGo to the Code tab\n\nTick “Use native pipe operator, l&gt; (requires R 4.1+)”\n\nGo to the RMarkdown tab\n\nUn-tick “Show output inline for all R Markdown documents”\n\n\nWhile we are here, if you wanted to change the font size or theme, you can do that in the Appearance tab.\nRStudio also has screenreader support. You can enable that in the Accessibility tab.\n\n\n\nI strongly recommend you create a folder where you save all the work you do as part of this course. I also recommend you make this folder in a part of your computer that is not being synced with a cloud service (iCloud, OneDrive, Google Drive, Dropbox, etc). These services can cause issues with RStudio. You can always back up your work at the end of a session.\nWithin your new course folder, I also want you to make a new folder for each exercise we do. This will make it very easy for you to stay organsied and submit work you do to me for feedback. It also makes your code reproducible by simply sending someone the contents of the folder in question. For example, this is exercise 4, so my main folder might be called biob11, and within that folder I might make a folder called exercise_4.\nWe now want to set our working directory to this biob11/exercise_4 folder. A working directory is the directory (folder) in a file system where a user is currently working. It is the default location where all your R code will be executed and where files are read from or written to unless specified otherwise. To set the working directory using RStudio, go to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise. You should do this at the start of each exercise.\nNotice that now in your Output pane, in the files tab, you can see the contents of your folder (which is probably nothing currently). Let’s change that.\n\n\n\nLet’s save this example RMarkdown document that RStudio has made for us. You do that exactly how you might expect. Go to File -&gt; Save, or use the floppy disc icon. Ensure you save it in your working directory with a descriptive name (e.g. exercise_4.Rmd). The file should have appeared in your Output pane, with the extension .Rmd.\nLet’s move onto working with some data!"
  },
  {
    "objectID": "exercises/04_handling_data.html#rmarkdown",
    "href": "exercises/04_handling_data.html#rmarkdown",
    "title": "Handling data using RStudio",
    "section": "",
    "text": "RMarkdown is a file format for making dynamic documents with R. It combines plain text with embedded R code chunks that are run when the document is rendered, allowing you to include results and your R code directly in the document. This makes it a powerful tool for creating reproducible analyses, which are extremely important in science.\nThe RMarkdown document you opened has some example text and code. An RMarkdown document consists of three main parts:\n\nYAML Header: This section, enclosed by --- at the beginning and end, contains metadata about the document, such as the title, author, date, and output format.\nText: You can write plain text using Markdown syntax to format it. Markdown is a lightweight markup language with plain text formatting syntax, which is easy to read and write.\nCode Chunks: These are sections of R code enclosed by triple backticks and {r}. You can click the green arrow to run all the code in a code chunk, or run each line of code using the Run button, or by using Ctrl+Enter (Windows) or Cmd+Enter (macOS)When the document is rendered, the code is executed, and the results are included in the output.\n\nNotice at the top left of the Source panel, there are two buttons: Source and Visual. These allow you to switch betwee two views of the RMarkdown document. The Source view is what you are looking at, and it is the raw text document. You can also use the Visual view, which allows you to work in a WYSIWYG (what you see is what you get) view, similar to Microsoft Office or other text editors. This “renders” your markdown code for you while you write. It also gives you a series of menus to help you format text, which means you do not need to learn how to write markdown code (although it is extremely simple, and you likely know some already).\nWhich ever view you prefer (and you can switch as often as you like), the code part stays the same. It is primarily there for editing the text around your code."
  },
  {
    "objectID": "exercises/04_handling_data.html#important-settings",
    "href": "exercises/04_handling_data.html#important-settings",
    "title": "Handling data using RStudio",
    "section": "",
    "text": "Before we go any further, we need to change some default settings in RStudio.\nGo to Tools -&gt; Global Settings, then:\n\nGo to the General tab.\n\nUn-tick “Restore .RData into workspace at startup”\nSet “Save workspace to RData on exit:” to Never.\n\nGo to the Code tab\n\nTick “Use native pipe operator, l&gt; (requires R 4.1+)”\n\nGo to the RMarkdown tab\n\nUn-tick “Show output inline for all R Markdown documents”\n\n\nWhile we are here, if you wanted to change the font size or theme, you can do that in the Appearance tab.\nRStudio also has screenreader support. You can enable that in the Accessibility tab."
  },
  {
    "objectID": "exercises/04_handling_data.html#working-directory",
    "href": "exercises/04_handling_data.html#working-directory",
    "title": "Handling data using RStudio",
    "section": "",
    "text": "I strongly recommend you create a folder where you save all the work you do as part of this course. I also recommend you make this folder in a part of your computer that is not being synced with a cloud service (iCloud, OneDrive, Google Drive, Dropbox, etc). These services can cause issues with RStudio. You can always back up your work at the end of a session.\nWithin your new course folder, I also want you to make a new folder for each exercise we do. This will make it very easy for you to stay organsied and submit work you do to me for feedback. It also makes your code reproducible by simply sending someone the contents of the folder in question. For example, this is exercise 4, so my main folder might be called biob11, and within that folder I might make a folder called exercise_4.\nWe now want to set our working directory to this biob11/exercise_4 folder. A working directory is the directory (folder) in a file system where a user is currently working. It is the default location where all your R code will be executed and where files are read from or written to unless specified otherwise. To set the working directory using RStudio, go to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise. You should do this at the start of each exercise.\nNotice that now in your Output pane, in the files tab, you can see the contents of your folder (which is probably nothing currently). Let’s change that."
  },
  {
    "objectID": "exercises/04_handling_data.html#saving-your-document",
    "href": "exercises/04_handling_data.html#saving-your-document",
    "title": "Handling data using RStudio",
    "section": "",
    "text": "Let’s save this example RMarkdown document that RStudio has made for us. You do that exactly how you might expect. Go to File -&gt; Save, or use the floppy disc icon. Ensure you save it in your working directory with a descriptive name (e.g. exercise_4.Rmd). The file should have appeared in your Output pane, with the extension .Rmd.\nLet’s move onto working with some data!"
  },
  {
    "objectID": "exercises/04_handling_data.html#setting-up-the-rmarkdown-document",
    "href": "exercises/04_handling_data.html#setting-up-the-rmarkdown-document",
    "title": "Handling data using RStudio",
    "section": "Setting up the RMarkdown document",
    "text": "Setting up the RMarkdown document\nWe will work with the RMarkdown file we generated at the start (that I called exercise_4.Rmd).\nFirst, we should delete all the code and text that RStudio automatically generated, except the YAML header (the text at the start between the ---). You can do that as you would expect in any other text editor. Now we have our blank RMarkdown file, let’s get started."
  },
  {
    "objectID": "exercises/04_handling_data.html#installing-r-packages",
    "href": "exercises/04_handling_data.html#installing-r-packages",
    "title": "Handling data using RStudio",
    "section": "Installing R packages",
    "text": "Installing R packages\nIn this exercise, we will use the tidyverse package, and the infer package. To install them you need to use the install.packages() function. Since we only need to do this once per computer, we should run this function directly in the Console panel.\nType or copy the install function into the console, and press enter to run:\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"infer\")\n\n\nFrom now on, we won’t write things directly in the Console, and instead write code in the RMarkdown document in the Source panel, which we then “Run” and send the Console."
  },
  {
    "objectID": "exercises/04_handling_data.html#creating-code-cells",
    "href": "exercises/04_handling_data.html#creating-code-cells",
    "title": "Handling data using RStudio",
    "section": "Creating code cells",
    "text": "Creating code cells\nCode cells are where we write code in an RMarkdown document. This allows use to write normal text outside these sections.\nIn your Source panel, in the RMarkdown document, add a R code cell.\n\n\n\n\n\n\nVisual view\n\n\n\n\n\nTo do that in the Visual view (where the text is rendered), go to Insert -&gt; Executable Cell -&gt; R.\n\n\n\n\n\n\n\n\n\n\nSource view\n\n\n\n\n\nTo do that in the Source view (where we see just plain text), we use three back-ticks (```) to mark the start and end of a code cell. Additionally at the start, we declare the language used by enclosing it in two curly brackets {r}.\n```{r}\n\n```\n\n\n\nIn both views, you can also use the shortcut Shift-Alt-I or Shift-Command-I."
  },
  {
    "objectID": "exercises/04_handling_data.html#loading-r-packages",
    "href": "exercises/04_handling_data.html#loading-r-packages",
    "title": "Handling data using RStudio",
    "section": "Loading R packages",
    "text": "Loading R packages\nAfter installing an R package, we need to load it into our current R environment. We use the library() function to do that. Since we need this code to run every time we come back to this RMarkdown document, we should write it in the document. R code should always be executed “top to bottom”, so this bit of code should come right at the start.\nInside that code cell you just made, use the library() function to load the tidyverse and infer packages:\n(To run code in the Source panel, you can click on the line you want to run, and then press the “Run” button. Or you can also use the keyboard shortcut Ctrl+Enter or Cmd+Return.)\n\nlibrary(tidyverse)\nlibrary(infer)\n\nIf that worked, you will get a message that reads something similar to:\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThis message tells us which packages were loaded by the tidyverse package, and which functions from base R (the functions that come with R by default) have been overwritten by the tidyverse packages. Not all packages produce a message when they are loaded (for example, infer did not)."
  },
  {
    "objectID": "exercises/04_handling_data.html#adding-headings-and-text",
    "href": "exercises/04_handling_data.html#adding-headings-and-text",
    "title": "Handling data using RStudio",
    "section": "Adding headings and text",
    "text": "Adding headings and text\nAnywhere outside a code cell you can write normal text. In this course, you might find it helpful to write yourself notes alongside your code, so that you can come back to your notes during other exercises, the exam (open book), the group project, or later in your studies.\nAlong side normal text, you can structure an RMarkdown document using headings.\n\n\n\n\n\n\nVisual view\n\n\n\n\n\nChange the type of text you are typing in the menu at the top:\n\n\n\n\n\n\n\n\n\n\nSource view\n\n\n\n\n\nUse #s to indicate the level of the heading:\n# Heading level 1\n## Heading level 2\n### Heading level 3\n\n\n\nI leave it up to you to decide how and when to use headings and text."
  },
  {
    "objectID": "exercises/04_handling_data.html#importing-data-into-r",
    "href": "exercises/04_handling_data.html#importing-data-into-r",
    "title": "Handling data using RStudio",
    "section": "Importing data into R",
    "text": "Importing data into R\nWe will now load the tephritis_phenotype.csv data file that you downloaded earlier. A .csv file is a file that stores information in a table-like format with Comma Separated Values. A typical .csv file will look something like this:\nspecies,height,n_flowers\npersica,1.2,12\npersica,1.5,18\nbanksiae,2.4,3\nbanksiae,1.7,8\n.csv files are especially suited to storing data that can be used across a wide variety of programmes, as everything is stored as plain text (unlike an .xlsx file from Microsoft Excel, for example).\nMake another code cell.\nLoad the tephritis_phenotype.csv data file using the read_csv() function and assign it to an object named tephritis_data.\n\n1tephritis_data &lt;- read_csv(\"tephritis_phenotype.csv\")\n\n\n1\n\nBe sure to use quote marks around the file name.\n\n\n\n\nIf that worked, you should get the following message with some information about the data:\n\n\nRows: 583 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): region, host_plant, patry, sex, baltic\ndbl (5): body_length_mm, ovipositor_length_mm, wing_length_mm, wing_width_mm...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis has loaded a copy of the data from tephritis_phenotype.csv into R. Notice that the object tephritis_data has also appeared in the Environment panel.\n\nClick on the object tephritis_data with your mouse. This will open the dataset using the RStudio function View() (which if you look in your console, you will see it has just run). This allows you to view the dataset as a table, like you would in a spreadsheet software like Microsoft Excel. Note however, there is no way to edit the data in this view. This is by design. Any editing of the data needs to be done in the RMarkdown document with code. That way, you can keep a record of any edits you make, without touching the original data file."
  },
  {
    "objectID": "exercises/04_handling_data.html#exploring-data",
    "href": "exercises/04_handling_data.html#exploring-data",
    "title": "Handling data using RStudio",
    "section": "Exploring data",
    "text": "Exploring data\nLet’s use a few more functions to get a better understanding of the dataset. You may remember these from Exercise 2. Make a new code cell, and write the following:\n\n1print(tephritis_data)\n\n\n1\n\nWe can also just simply write tephritis_data without the print statement, and we would get the same output.\n\n\n\n\nWe can also use glimpse() for an alternative view:\n\nglimpse(tephritis_data)\n\nYou can also use the summary() function:\n\nsummary(tephritis_data)\n\nIn your RMarkdown document, using text below the code cell, answer the following questions:\n\nWhat is the unit of observation in this data set? In other words, what does each row represent?\nWhat populations (statistical use of the word) could we make inferences about using this data?\nWhat type of variable is:\n\nregion\nhost_plant\npatry\nsex\nbody_length_mm\novipositor_length_mm\nwing_length_mm\nwing_width_mm\nmelanized_percent\nbaltic\n\n\nAre there any NA values in the dataset? In which variable(s) and why might this be?"
  },
  {
    "objectID": "exercises/04_handling_data.html#cleaning-data",
    "href": "exercises/04_handling_data.html#cleaning-data",
    "title": "Handling data using RStudio",
    "section": "Cleaning data",
    "text": "Cleaning data\nDatasets can often be messy. People make mistakes entering data all the time. You should check this dataset for potential errors. For a reference, these flies are very small, less than 1 cm in size.\nMake a new code cell for cleaning your data.\n\nUse the output of summary() to help you check for potential errors.\nYou can also, as you did before, click on the object tephritis_data in your Environment panel, and click on each variable header to sort it in different ways.\nFor any suspicious variables where you think there might be mistakes, a good first approach is to plot your data. Use code adapted from previous exercises to make histograms to check your data for potential mistakes.\n\nFor example, in the histograms and box plots below both with an outlier point. Hopefully you can see the difference between an outlier (“Probably not a mistake”) and a real mistake (“Probably a mistake”). Remember, outliers are part of real data, and we should not remove them just because they are outliers. But they do have to be plausible to be kept.\n\n\n\n\n\n\n\n\n\nWhich variables do you think might have incorrectly entered data?\nWe will use a filter() function to inspect rows that contain improbably values. filter() let’s us write conditional statements (from Exercise 1) that only allow rows that meet those conditions to “filter” through. For example, we could use filter to see all rows where wing_length_mm is greater than our guess at what the maximum should be. Looking at the histogram of wing_length_mm, and with the knowledge that these flies are &lt; 1 cm in size, adapt the following code to just show you the suspicious rows:\n\n1tephritis_data |&gt; filter(wing_length_mm &gt; _____)\n\n\n1\n\nThis will only let though rows that have a wing_length_mm greater than &gt; _____\n\n\n\n\nWhat do you think? Do these values seem real, or are they probably mistakes? Use the code above to check your other suspicious variables. If you think these values are mistakes, then we need to get rid of them.\nAn easy way to do that is to use filter() again, but this time, to only allow rows that do have plausible values to “filter” through. That is, we can reverse the greater than &gt; to a less than &lt;. If we wanted to set a lower limit, we could that by using the & operator (from Exercise 1). We can also chain together filter() functions using pipes |&gt; to clean up our dataset in one go. Adapt the code below to clean up the dataset:\n\n1clean_data &lt;-\n  tephritis_data |&gt; \n  filter(wing_length_mm &lt; _____) |&gt;\n2  filter(______ ______ ______)\n\n\n1\n\nI assigned the cleaned data to a new object, called clean_data.\n\n2\n\nYou can add more filter() functions as you wish.\n\n\n\n\nUse the summary() function again, and make some plots to show that your data cleaning has had the desired effect."
  },
  {
    "objectID": "exercises/04_handling_data.html#descriptive-statistics",
    "href": "exercises/04_handling_data.html#descriptive-statistics",
    "title": "Handling data using RStudio",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\nMake a new code cell. Inside it, write or adapt code from previous exercises to answer the following questions:\n\nWhat is the overall mean and standard deviation of:\n\nbody_length_mm\novipositor_length_mm\nwing_length_mm\nwing_width_mm\n\nWhat are the sex specific means and standard deviations of:\n\nbody_length_mm\nwing_length_mm\nwing_width_mm\n\nWhat are the sex and host_plant specific means and standard deviations of:\n\nbody_length_mm\novipositor_length_mm\nwing_length_mm\nwing_width_mm\n\n\nHint: You will probably want to use the functions group_by() and summarise()."
  },
  {
    "objectID": "exercises/04_handling_data.html#exploratory-plots",
    "href": "exercises/04_handling_data.html#exploratory-plots",
    "title": "Handling data using RStudio",
    "section": "Exploratory plots",
    "text": "Exploratory plots\nIn a new code cell, use what you have learned in previous exercises to make some figures that explore the following relationships:\n\nbody_length_mm and sex\novipositor_length_mm and host_plant\nwing_length_mm and wing_width_mm and sex\nThe number of flies measured from each region and host_plant\n\nYou should use the following geom_s at least once, but one plot can use multiple geom_s.\ngeom_point() geom_jitter() geom_boxplot() geom_violin() geom_bar()\nTo find out what they do, try using them, or search the helpfiles in the Outputs panel. You can also, for any function, search for the helpfile by writing ?function_name. E.g., if you wanted to know what geom_jitter() does, you could run the command ?geom_jitter, and the helpfile will open.\nYou can also consult the ggplot2 “cheatsheet” for help.\nWhile making your plots, keep the following “best practises” in mind:\nA good plot should:\n\nShow the data\nMake patterns in the data easy to see\nRepresent magnitudes honestly\nDraw graphical elements clearly\n\nggplot2 allows for extensive customisation of your plots. For example, you might want to change the labels of the axis, or give your plot a title. You can do that using the labs() function:\n\nggplot(example_data, aes(x = variable_1, y = variable_2)) +\ngeom_points() +\nlabs(x = \"Name of my x variable\", y = \"Name of my Y variable\", title = \"My awesome plot\")\n\nYou can also change the theme of your plot. ggplot2 has many built in themes. A full list can be found here. For my fake example, I could change the theme to theme_classic() like this:\n\nggplot(example_data, aes(x = variable_1, y = variable_2)) +\ngeom_points() +\ntheme_classic()\n\nTry it out on your plots. What theme do you prefer best?\nIn general, ggplot2 is a very widely used plotting package, so finding examples of what you want to do will not be hard. Use search engines, AI tools, the ggplot2 book, etc. If you see it on your plot, you can probably change it."
  },
  {
    "objectID": "exercises/04_handling_data.html#data-analysis",
    "href": "exercises/04_handling_data.html#data-analysis",
    "title": "Handling data using RStudio",
    "section": "Data analysis",
    "text": "Data analysis\nWe will finish this exercise with an analysis similar to Exercise 2. Again, we will cover the theory behind these analyses more in depth during the lectures.\nMake a new section in your R markdown file, with a new code cell(s). Make notes outside the code cells which you can refer back to at a later date.\nRecall that the researchers measured flies that live in two different host plants. Although they are the same species, the use of these two different host plants functionally splits the species into two “host races”, that do not reproduce with each other.\nSuppose the researchers have evidence to suggest that, before the species was split by colonizing these two host plants, the ancestral fly had a mean ovipositor length of 1.79 mm. The researchers want to know if either of the two host races have evolved a different ovipositor length, perhaps to better adapt to their new host plants.\nFor now, let’s focus on the heterophyllum host race.\nWe want to answer the question:\nIs the mean ovipositor_length_mm in the heterophyllum host race different from 1.79 mm?\n\nHypotheses\nFrom this research question:\n\nWhat population are we making inferences about?\nWhat is the null hypothesis?\nWhat is the alternative hypothesis?\n\n\n\nCollecting data\nAs we are just interested in the flies that hatched from the heterophyllum host_plant, we should first make a subset of our data that is just the data we are going to use. Use filter() to create a dataset that only has:\n\nflies that hatched from the heterophyllum host_plant\nfemale sex flies (as males do not have ovipositors)\n\nThe conditional statement == will be useful here.\nName this dataset something meaninful, like heterophyllum_data, or maybe something shorter if you prefer, like h_data.\n\n\nPlotting data\nUsing this new dataframe, make a plot that illustrates your hypothesis.\n\n\nCalculating the test statistic\nFirst, we need to know what our test statistic, in this case the mean ovipositor_length_mm length we observe in our sample is. This is called our observed (test) statistic. To calculate this, we can use specify() and calculate(). First, we should pipe |&gt; our filtered dataset into the specify() function. Inside specify(), we need to declare which variable we are interested in. In this case, we only have a response variable, as we are just working with the mean of one group. We then pipe |&gt; that into calculate(), where we declare the name of our chosen test statistic. We save it as observed_mean_h, as we want to use it later to compare against a null distribution.\n\nobserved_mean_h &lt;- \n  ____________ |&gt;\n  specify(response = ______) |&gt;\n  calculate(stat = \"______\")\n\nobserved_mean_h\n\n\n\nSimulating data under the null hypothesis\nNext we need a null distribution to compare with. First, we need to imagine that the null hypothesis is true. In this case, that mean ovipositor_length_mm == 1.79. To do that, we create a new dataset from our sample, where the mean ovipositor_length_mm == 1.79. We do that by using the difference between the mean in our sample 1.76 and mean we want to test against (1.79) to shift our data such that it is compatible with the null hypothesis. We then draw “bootstrap” replicates (sampling with replacement) from this new data and calculate our test statistic (mean) each time. Like in the example in exercise 2, we need to do this a lot of times to generate an appropriate null distribution (in this case, 10000 times).\n\nnull_dist_h &lt;-\n  ______ |&gt;\n  specify(response = ______) |&gt;\n  hypothesize(null = \"point\", mu = ______) |&gt;\n  generate(reps = ______, type = \"bootstrap\") |&gt;\n  calculate(stat = \"______\")\n\n\n\nComparing our observed statistic to the null distribution\nWe can now use visualize() to show our null distribution, and the function shade_p_value() to show our observed statistic, and the proportion of the null distribution that is more extreme than our observed statistic. The direction you choose relates to your original alternative hypothesis.\n\nIf your alternative hypothesis was that there would be a difference from 1.79 mm, but you didn’t specifiy if the evolved ovipositor would be longer or shorter (i.e., you didn’t predict a direction), then you should write \"two-sided\".\nIf your alternative hypothesis was that the evolved ovipositor would be longer, then your hypothesis was one-sided, and you should write \"greater\".\nIf your alternative hypothesis was that the evolved ovipositor would be shorter, then your hypothesis was one-sided, and you should write \"lesser\".\n\n\nnull_dist_h |&gt;\n  visualize() + \n  shade_p_value(observed_mean_h, direction = \"______\")\n\nWe can also calculate from this what our “p-value” is. In this case, our p-value corresponds to the proportion of the null distribution that as extreme, or more extreme than our observed statistic. You can think of it being the probability we would observe data (i.e., collect our sample) if the null hypothesis was true. The closer it is to 0, the more confident we are that the null-hypothesis is not correct.\n\nnull_dist_h |&gt;\n  get_p_value(obs_stat = observed_mean_h, direction = \"______\")\n\nWrite a few sentence to describe the outcome of your test. In addition to the describing the test, also phrase your findings in terms that a friend who isn’t taking this class could understand (i.e., what do your findings suggest, related back to the original question)."
  },
  {
    "objectID": "exercises/04_handling_data.html#save-your-rmarkdown-file",
    "href": "exercises/04_handling_data.html#save-your-rmarkdown-file",
    "title": "Handling data using RStudio",
    "section": "Save your RMarkdown file!",
    "text": "Save your RMarkdown file!\nMake sure you save your RMarkdown file regularly. If you want to turn it into a webpage similar to this one, you can click the “Knit” button, and it will appear in your Output panel."
  },
  {
    "objectID": "exercises/06_test_analysis.html",
    "href": "exercises/06_test_analysis.html",
    "title": "Test your skills",
    "section": "",
    "text": "Each time we start a new exercise, you should:\n\nMake a new folder in your course folder for the exercise (e.g. biob11/exercise_6)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\nWe are now ready to start."
  },
  {
    "objectID": "exercises/06_test_analysis.html#instructions",
    "href": "exercises/06_test_analysis.html#instructions",
    "title": "Test your skills",
    "section": "Instructions",
    "text": "Instructions\nYou should write a small report that answers the following question:\nDoes the addition of calcium impact sugar maple seedling growth?\nYour report should include:\n\nDescriptive statistics of the variables you think are important, with associated 95% confidence intervals when appropriate.\nIllustrative figures that you use to present your findings.\nAt least two clearly stated hypotheses, with the null and alternative, which you then test either using a bootstrap or randomisation approach.\nState your conclusions, refering to plots and the outcomes of your hypothesis tests.\n\nBefore you make your report, you will need to:\n\nImport the dataset and check it for errors.\n\nRemove any errors you find.\n\n\nIf you would like feedback on your report, you can submit it via Canvas as an .Rmd file here."
  },
  {
    "objectID": "exercises/08_chisq.html",
    "href": "exercises/08_chisq.html",
    "title": "Tests of, and associations between, categorical variables",
    "section": "",
    "text": "Each time we start a new exercise, you should:\n\nMake a new folder in your course folder for the exercise (e.g. biob11/exercise_8)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\nPlease ensure you have followed the step above before you start!"
  },
  {
    "objectID": "exercises/08_chisq.html#analysis",
    "href": "exercises/08_chisq.html#analysis",
    "title": "Tests of, and associations between, categorical variables",
    "section": "Analysis",
    "text": "Analysis\nWhile working on your analysis, answer the questions below:\n\nGeneral\n\nWhat (statistical) population are the researchers trying to make inferences about?\n\n\n\nData handling and plotting\n\nEnsure you have loaded the tidyverse and infer packages.\nImport the dataset using read_csv().\nWhat sort of variables are species and habitat?\nCheck the data for mistakes.\nMake an illustrative plot of the dataset using ggplot().\n\n\n\nDescriptive statistics\nReport the following statistics:\n\nThe proportion of each species that are found in each habitat.\n\n\n\nAre certain species associated with certain habitats\nThe researchers want to know if some species are much more likely to be found in one habitat than another, or are they randomly spread across the bay.\n\nState the null and alternative hypothesis.\nWhat test statistic will you use? Why?\nCalculate the observed test statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nobserved_statistic &lt;-\n1  ______ |&gt;\n2  specify(response = ______, explanatory = ______) |&gt;\n3  hypothesize(null = \"independence\") |&gt;\n4  calculate(stat = \"______\")\n\n5observed_statistic\n\n\n1\n\nThe name of the dataset.\n\n2\n\nSpecify which is your response and explanatory variable.\n\n3\n\nThe specific test statistic we want to use requires us to provide our null hypothesis. In this example, we want to know if the two variables are associated, so our null hypothesis is that they are independent.\n\n4\n\nCalculate the observed statistic.\n\n5\n\nPrint the observe statistic to the console.\n\n\n\n\n\n\n\n\nTo generate a null distribution, we can use a permutation approach, where we shuffle the assigned categories and calculate our statistic many many times. Generate a null distribution.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist &lt;-\n1  ______ |&gt;\n2  specify(response = ______, explanatory = ______) |&gt;\n3  hypothesize(null = \"independence\") |&gt;\n4  generate(reps = 10000, type = \"permute\") |&gt;\n5  calculate(stat = \"______\")\n\n\n1\n\nThe name of the dataset.\n\n2\n\nSpecify which is your response and explanatory variable.\n\n3\n\nOur hypothesis is that our response variable is independant of our explanatory variable.\n\n4\n\nSimulate data using permuations. This may take a few seconds to minutes depending on your computer.\n\n5\n\nFrom each of our simulated permutation samples, calculate the test statistic.\n\n\n\n\n\n\n\n\nPlot the null distribution and the observed statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n1  visualise() +\n2  shade_p_value(obs_stat = observed_statistic, direction = \"greater\") +\n3  labs(x = \"______ statistic\")\n\n\n1\n\nPipe your null_dist object into visualise().\n\n2\n\nPlot your observed_statistic, and specify that the direction should be greater. Our statistic is squared, so is naturally bounded at 0.\n\n3\n\nYou can change the axis labels to make the plot more clear.\n\n\n\n\n\n\n\n\nUse your observed statistic and your null distribution to calculate a p-value.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_statistic, direction = \"greater\")\n\n\n\n\n\nWhat are your conclusions? State them in terms of your null hypothesis, and in a more general statement."
  },
  {
    "objectID": "exercises/08_chisq.html#analysis-1",
    "href": "exercises/08_chisq.html#analysis-1",
    "title": "Tests of, and associations between, categorical variables",
    "section": "Analysis",
    "text": "Analysis\nWhile working on your analysis, answer the questions below:\n\nGeneral\n\nWhat (statistical) population are the researchers trying to make inferences about?\n\n\n\nData handling and plotting\n\nEnsure you have loaded the tidyverse and infer packages.\nImport the dataset using read_csv().\nWhat sort of variables is party?\nCheck the data for mistakes.\nMake an illustrative plot of the dataset using ggplot(). Can you show the expected values on the plot as well?\n\n\n\nDescriptive statistics\nReport the following statistics:\n\nThe proportion of the people surveyed who said they would vote for each party.\n\n\n\nHas public opinion changed since the election?\n\nState the null and alternative hypothesis.\nWhat test statistic will you use? Why?\nCalculate the observed test statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nobserved_statistic &lt;- \n1  _____ |&gt;\n2  specify(response = _____) |&gt;\n  hypothesize(\n3    null = \"point\",\n    p = c(\n4      \"______\" = ______,\n      \"______\" = ______,\n      \"______\" = ______,\n      \"______\" = ______,\n      \"______\" = ______\n    )\n   ) |&gt;\n5  calculate(stat = \"______\")\n\n6observed_statistic\n\n\n1\n\nThe name of the dataset.\n\n2\n\nSpecify which is your response variable.\n\n3\n\nThe specific test statistic we want to use requires us to provide our null hypothesis. In this example, we want to know if the proportion of each group in the response variable is different from a hypothesised proportion, so we use point.\n\n4\n\nHere we need to put in our expected or hypothesised proportions under the null hypothesis.\n\n5\n\nCalculate the observed statistic.\n\n6\n\nPrint the observe statistic to the console.\n\n\n\n\n\n\n\n\nTo generate a null distribution, we can draw from a probability distribution defined by our hypothesize() step.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist &lt;-\n1  _____ |&gt;\n2  specify(response = _____) |&gt;\n  hypothesize(\n3    null = \"point\",\n    p = c(\n4      \"______\" = ______,\n      \"______\" = ______,\n      \"______\" = ______,\n      \"______\" = ______,\n      \"______\" = ______\n    )\n   ) |&gt;\n5   generate(reps = 10000, type = \"draw\") |&gt;\n6  calculate(stat = \"______\")\n\n\n1\n\nThe name of the dataset.\n\n2\n\nSpecify your response variable.\n\n3\n\nIn this example, we want to know if the proportion of each group in the response variable is different from a hypothesised proportion, so we use point.\n\n4\n\nHere we need to put in our expected or hypothesised proportions under the null hypothesis.\n\n5\n\nSimulate data using draw\n\n6\n\nFrom each of our simulated samples, calculate the test statistic.\n\n\n\n\n\n\n\n\nPlot the null distribution and the observed statistic.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n1  visualise() +\n2  shade_p_value(obs_stat = observed_statistic, direction = \"greater\") +\n3  labs(x = \"______ statistic\")\n\n\n1\n\nPipe your null_dist object into visualise().\n\n2\n\nPlot your observed_statistic, and specify that the direction should be greater. Our statistic is squared, so is naturally bounded at 0.\n\n3\n\nYou can change the axis labels to make the plot more clear.\n\n\n\n\n\n\n\n\nUse your observed statistic and your null distribution to calculate a p-value.\n\n\n\n\n\n\n\nCode hint\n\n\n\n\n\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_statistic, direction = \"greater\")\n\n\n\n\n\nWhat are your conclusions? State them in terms of your null hypothesis, and in a more general statement."
  },
  {
    "objectID": "exercises/10_test_analysis_2.html",
    "href": "exercises/10_test_analysis_2.html",
    "title": "Test your skills II",
    "section": "",
    "text": "Get RStudio setup\nEach time we start a new exercise, you should:\n\nMake a new folder in your course folder for the exercise (e.g. biob11/exercise_10)\nOpen RStudio\n\nIf you haven’t closed RStudio since the last exercise, I recommend you do so and then re-open it. If it asks if you want to save your R Session data, choose no.\n\nSet your working directory by going to Session -&gt; Set working directory -&gt; Choose directory, then navigate to the folder you just made for this exercise.\nCreate a new Rmarkdown document (File -&gt; New file -&gt; R markdown..). Give it a clear title.\n\nPlease ensure you have followed the step above before you start!\n\n\nLake ice coverage and air temperature\nThis dataset contains records of ice formation on two lakes (lakeid) since the mid 1800s. The ice_on date refers to the first day in the winter of year where the lake fully froze, and ice_off refers to the date the following spring where the ice fully melted. avg_air_temp_adjusted is the mean temperature during the winter of year.\nThe dataset, lake_ice.csv can be found here.\nUse this dataset to answer these broad research questions:\n\nHas the total amount of time each lake spends frozen each winter changed?\nIs this change associated with air temperature?\nIn general, does one lake stay frozen for longer than the other?\n\nRemember:\n\nState clearly the research question, and what your hypotheses were. Explain why these hypotheses answer your research question.\nExplain your choice of test statistic/method. Relate this to your hypotheses and question.\nState your observed statistics(s) and confidence intervals. Explain what these mean. Refer to plots you have made.\nState the outcome of your hypothesis test (quoting test statistIc(s) and p-values). Interpret this result, in both terms of your statistical hypothesis, but also the broad research question.\n\n\n\n\n\n\n\nHint about dates in R\n\n\n\n\n\n\nlibrary(tidyverse, quietly = TRUE)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndate1 &lt;- ymd(\"2025-04-04\")\ndate2 &lt;- ymd(\"2025-04-01\")\n\ndays_difference &lt;- date1 - date2\ndays_difference\n\nTime difference of 3 days"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BIOB11 - Experimental Design and Analysis for Biologists",
    "section": "",
    "text": "Welcome to the course website for BIOB11. Here you will find all materials used in the course.\nAll course communication should take place on LU Canvas. This site is only for hosting interactive materials that are not easy to distribute as files via Canvas.\nThis website uses the webR WebAssembly engines to dynamically execute R code in your web browser so I can provide you with interactive exercises.1",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "BIOB11 - Experimental Design and Analysis for Biologists",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis means with a slow internet connection, or a slower browser/computer (especially mobile devices that place restricitons on browser RAM usage), you may experience a delay between loading a page and being able to use the interactive R console, and/or a delay in executing code in the R console. If you have any issues, let the course teacher know.↩︎",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "During this course, we will make reference to the following books. None of these books are intended to be read “cover to cover”. Instead, we will reference the relevant chapters at each part of the course. All the books have a high degree of topic overlap, but explain the key concepts slightly differently.\nPlease do not feel pressured to buy a copy of Ennos & Johnsson (2018) if you do not want to (note the library has some copies). It is a good book, but the other free books I have listed below cover all the same topics.\n\n\n\n\n\nStatistical and data handling skills in biology, 4th ed., Ennos & Johnsson (2018)\n\n\n\n\n\n\n\n\nR for Data Science, 2nd ed., Wickham, Çetinkaya-Rundel & Grolemund (2023) (R reference book)\nR Markdown: The Definitive Guide, Xie, Allaire & Grolemund (2023) (RMarkdown reference book)\n\n\n\n\n\nStatistical Inference via Data Science 2nd ed., Ismay, Kim & Valdivia (2025) (Ch. 1-4, 7-9)\nIntroduction to Modern Statistics, 2nd ed,. Çetinkaya-Rundel & Hardin (2024) (Ch. 2, 11-22)\n\n\n\n\n\nFundamental statistical concepts and techniques in the biological and environmental sciences, 1st ed. Duthie (2025)\n\nAlso available as an audiobook",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#physical-books",
    "href": "resources.html#physical-books",
    "title": "Resources",
    "section": "",
    "text": "Statistical and data handling skills in biology, 4th ed., Ennos & Johnsson (2018)",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#online-books",
    "href": "resources.html#online-books",
    "title": "Resources",
    "section": "",
    "text": "R for Data Science, 2nd ed., Wickham, Çetinkaya-Rundel & Grolemund (2023) (R reference book)\nR Markdown: The Definitive Guide, Xie, Allaire & Grolemund (2023) (RMarkdown reference book)\n\n\n\n\n\nStatistical Inference via Data Science 2nd ed., Ismay, Kim & Valdivia (2025) (Ch. 1-4, 7-9)\nIntroduction to Modern Statistics, 2nd ed,. Çetinkaya-Rundel & Hardin (2024) (Ch. 2, 11-22)\n\n\n\n\n\nFundamental statistical concepts and techniques in the biological and environmental sciences, 1st ed. Duthie (2025)\n\nAlso available as an audiobook",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#r-packages",
    "href": "resources.html#r-packages",
    "title": "Resources",
    "section": "R packages",
    "text": "R packages\nWe will make use of a set of R packages that are part of the extended tidyverse set of packages. Below are the websites for the main ones we will use, which contain guides, cheatsheets and reference materials.\n\nGeneral\n\ntidyverse\n\nggplot2 (Plotting data)\ndplyr (Manipulating data)\ntidyr (Tidying data)\nreadr (Importing/exporting data)\n\n\n\n\nStatistics\n\ninfer",
    "crumbs": [
      "Resources"
    ]
  }
]